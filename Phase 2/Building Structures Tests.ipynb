{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import nltk\n",
    "from math import sqrt\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "class Infix(object):\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "    def __or__(self, other):\n",
    "        return self.func(other)\n",
    "    def __ror__(self, other):\n",
    "        return Infix(partial(self.func, other))\n",
    "    def __call__(self, v1, v2):\n",
    "        return self.func(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load():\n",
    "    ppp = nltk.data.load('../../Downloads/ppp.txt', encoding='utf8')\n",
    "    words_p = nltk.tokenize.wordpunct_tokenize(ppp)[130:]\n",
    "    alw = nltk.data.load('../../Downloads/alw.txt', encoding='utf8')\n",
    "    words_a = nltk.tokenize.wordpunct_tokenize(alw)[143:]\n",
    "    words = words_a + words_p\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_nodes = 100\n",
    "def process(KB, embeddings, sentence):\n",
    "    def next_lvl(sentence):\n",
    "        @Infix\n",
    "        def to(a, b):\n",
    "            x = embeddings[sentence[b]] - embeddings[sentence[a]]\n",
    "            return x\n",
    "        \n",
    "        nl = []\n",
    "        for index in range(len(sentence[:-1])):\n",
    "            if KB.has_edge(sentence[index], sentence[index+1]):\n",
    "                nl.append(KB[sentence[index]][sentence[index+1]]['node'])\n",
    "            else:\n",
    "                if KB.number_of_nodes()+1 < max_nodes:\n",
    "                    KB.add_node(KB.number_of_nodes(), exp=.5)\n",
    "                    KB.add_edge(sentence[index], sentence[index+1],\n",
    "                               node=KB.number_of_nodes())\n",
    "                    embeddings[KB.number_of_nodes()] = index |to| (index+1)\n",
    "                else:\n",
    "                    x = index |to| (index+1)\n",
    "                    similarity = cosine_similarity(embeddings, [x])\n",
    "                    nearest = np.argmax(similarity)\n",
    "                    exp = KB.node[nearest]['exp']\n",
    "                    embeddings[nearest] = embeddings[nearest]*exp + x*(1-exp)\n",
    "                    KB.node[nearest]['exp'] += (1-exp)**3\n",
    "                    if 1-similarity.max() > 1-exp:\n",
    "                        nl.append(nearest)\n",
    "                    \n",
    "                    if not KB.has_edge(sentence[index], sentence[index+1]):\n",
    "                        KB.add_edge(sentence[index], sentence[index+1], \n",
    "                                    node=nearest)\n",
    "        return nl\n",
    "    l_all = [sentence]\n",
    "    l_next = sentence\n",
    "    while l_next:\n",
    "        print(l_next)\n",
    "        l_next = next_lvl(l_next)\n",
    "        l_all += [l_next]\n",
    "    return KB, embeddings, l_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings = np.zeros((100, 100))\n",
    "for i in range(10):\n",
    "    embeddings[i] += np.random.random(size=100)\n",
    "KB = nx.DiGraph()\n",
    "KB.add_nodes_from(np.arange(10), exp=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "[22, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38]\n",
      "[40, 41, 43, 44, 44, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "[61, 63, 64, 65, 66, 67, 67, 67, 56, 57, 67, 67]\n",
      "[69, 70, 71, 72, 73, 67, 67, 74, 67, 75, 67]\n",
      "[81, 82, 83, 84, 85, 67, 86, 87, 78, 79]\n",
      "[98, 99, 93]\n"
     ]
    }
   ],
   "source": [
    "KB, embeddings, sentence = process(KB, embeddings, [i for i in range(10,25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
