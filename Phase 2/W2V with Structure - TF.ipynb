{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import math\n",
    "from six.moves import xrange\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-3cf80a8b9c49>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-3cf80a8b9c49>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    try list().extend[4]\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "try \n",
    "except IndexError:\n",
    "    print(\"H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.DiGraph.get_edge_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "class Infix(object):\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "    def __or__(self, other):\n",
    "        return self.func(other)\n",
    "    def __ror__(self, other):\n",
    "        return Infix(partial(self.func, other))\n",
    "    def __call__(self, v1, v2):\n",
    "        return self.func(v1, v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load():\n",
    "    ppp = nltk.data.load('../../Downloads/ppp.txt', encoding='utf8')\n",
    "    words_p = nltk.tokenize.wordpunct_tokenize(ppp)[130:]\n",
    "    alw = nltk.data.load('../../Downloads/alw.txt', encoding='utf8')\n",
    "    words_a = nltk.tokenize.wordpunct_tokenize(alw)[143:]\n",
    "    words = words_a + words_p\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn into list of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sentences(words):\n",
    "    sentences_word  = []\n",
    "    sent_word = []\n",
    "    for index, word in enumerate(words):\n",
    "        if word in ['?','.','!']:\n",
    "            sent_word += [word]\n",
    "            sentences_word += [sent_word]\n",
    "            sent_word = []\n",
    "        else:\n",
    "            sent_word += [word]\n",
    "    return sentences_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn Vocab into Indices\n",
    "-- This was process, but I think this is useful regardless. I will need to change it to accomodate ..... stuff?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(words, vocabulary_size):\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0  # dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Graph Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically we want to make sure that things are being added to the graph. How do we do this. Well. I think we should take them as if they were read in line and then only add things like that. This way we can do all our learning right good without having to stop and add to the graph\n",
    "\n",
    "Adding node likelihood : http://ieeexplore.ieee.org/document/7266560/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph(KB, embeddings, sentence, max_nodes):\n",
    "    def next_lvl(sentence):\n",
    "        @Infix\n",
    "        def to(a, b):\n",
    "            x = embeddings[sentence[b]] - embeddings[sentence[a]]\n",
    "            return x\n",
    "        \n",
    "        nl = []\n",
    "        ln = []\n",
    "        for index in range(len(sentence[:-1])):\n",
    "            if KB.has_edge(sentence[index], sentence[index+1]):\n",
    "                nl.append(KB[sentence[index]][sentence[index+1]]['node'])\n",
    "            else:\n",
    "                if KB.number_of_nodes()+1 < max_nodes:\n",
    "                    KB.add_node(KB.number_of_nodes(), exp=.5)\n",
    "                    KB.add_edge(sentence[index], sentence[index+1],\n",
    "                               node=KB.number_of_nodes())\n",
    "                    embeddings[KB.number_of_nodes()] = index |to| (index+1)\n",
    "                else:\n",
    "                    x = index |to| (index+1)\n",
    "                    similarity = cosine_similarity(embeddings, [x])\n",
    "                    nearest = np.argmax(similarity)\n",
    "                    exp = KB.node[nearest]['exp']\n",
    "                    embeddings[nearest] = embeddings[nearest]*exp + x*(1-exp)\n",
    "                    KB.node[nearest]['exp'] += (1-exp)**3\n",
    "                    if 1-similarity.max() > 1-exp:\n",
    "                        nl.append(nearest)\n",
    "                    \n",
    "                    if not KB.has_edge(sentence[index], sentence[index+1]):\n",
    "                        KB.add_edge(sentence[index], sentence[index+1], \n",
    "                                    node=nearest)\n",
    "        return nl\n",
    "    \n",
    "    \n",
    "    l_all = [sentence]\n",
    "    l_next = sentence\n",
    "    while l_next:\n",
    "        l_next = next_lvl(l_next)\n",
    "        print(l_next)\n",
    "        l_all += l_next\n",
    "    return KB, embeddings, l_all[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_graph(words):\n",
    "    KB2 = nx.Graph()\n",
    "    for word in words:\n",
    "        if not KB2.has_node(word):\n",
    "            KB2.add_node(word)\n",
    "        \n",
    "    KB3 = nx.convert_node_labels_to_integers(KB2, label_attribute='word')\n",
    "    KB4 = nx.Graph()\n",
    "    \n",
    "    for node in KB3.nodes(True):\n",
    "        KB4.add_node(node[1]['word'], number=node[0])\n",
    "    return KB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_level(words, embeddings, KB, n_cluster):\n",
    "    \n",
    "    for index, word in enumerate(words[:-1]):\n",
    "        if KB.has_node(word) and KB.has_node(words[index+1]):\n",
    "            if KB.has_edge(word, words[index+1]):\n",
    "                node_name = KB.edge[word][words[index+1]]['node']\n",
    "                words = np.insert(words, index+1, str(node_name))\n",
    "    \n",
    "    print(len(words))\n",
    "    data = [KB.node[word]['number'] for word in words if word in KB.node]\n",
    "    \n",
    "    embed_data = np.array([embeddings[wordnum] for wordnum in data])\n",
    "    \n",
    "    next_lvl_raw = embed_data[1:] - embed_data[:-1]\n",
    "    next_lvl_cent = TFKMC(next_lvl_raw, n_clusters=n_cluster)\n",
    "\n",
    "    words_n = np.array([words[0]])\n",
    "    vocab_size = KB.number_of_nodes()\n",
    "    \n",
    "    for num in range(vocab_size, vocab_size+n_cluster):\n",
    "        KB.add_node(str(num), number=num)\n",
    "    \n",
    "    for i in range(len(next_lvl_cent.labels_)):\n",
    "        t = next_lvl_cent.labels_[i]\n",
    "        words_n = np.append(words_n, [str(t+vocab_size), words[i+1]])\n",
    "        KB.add_edge(words[i], words[i+1], node=str(t+vocab_size))\n",
    "        \n",
    "    \n",
    "    \n",
    "    return words_n, KB     \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Each Batch\n",
    "-- a useful thing would be for batches to be made of few words, a couple sentences, and then be taken from there. idk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_index = 0\n",
    "def gen_batch(data, batch_size, skip_window, num_skips):\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1 # [ skip_window target skip_window ]\n",
    "    buffer = collections.deque(maxlen=span)\n",
    "    for _ in range(span):\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    for i in range(batch_size // num_skips):\n",
    "        target = skip_window  # target label at the center of the buffer\n",
    "        targets_to_avoid = [ skip_window ]\n",
    "        for j in range(num_skips):\n",
    "            while target in targets_to_avoid:\n",
    "                target = random.randint(0, span - 1)\n",
    "            targets_to_avoid.append(target)\n",
    "            batch[i * num_skips + j] = buffer[skip_window]\n",
    "            labels[i * num_skips + j, 0] = buffer[target]\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    return batch, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the Actual Word2Vec Algorithm in TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def W2V(batch_size, embedding_size, skip_window, num_skips, valid_size,\n",
    "       valid_window, valid_examples, num_sampled, vocabulary_size,\n",
    "       num_steps, data, revdic):\n",
    "    graph = tf.Graph()\n",
    "    \n",
    "    with graph.as_default():\n",
    "        train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "        train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "        valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "        \n",
    "        with tf.device('/cpu:0'):\n",
    "            \n",
    "            embeddings = tf.Variable(\n",
    "                            tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "            embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "        \n",
    "        nce_weights = tf.Variable(\n",
    "            tf.truncated_normal([vocabulary_size, embedding_size], \n",
    "                               stddev=1.0 / math.sqrt(embedding_size)))\n",
    "        nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "        \n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.nce_loss(nce_weights, nce_biases, embed, train_labels,\n",
    "                          num_sampled, vocabulary_size))\n",
    "        optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
    "        \n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), \n",
    "                                     1, keep_dims=True))\n",
    "        normalized_embeddings = embeddings / norm\n",
    "        valid_embeddings = tf.nn.embedding_lookup(\n",
    "            normalized_embeddings, valid_dataset)\n",
    "        similarity = tf.matmul(\n",
    "            valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "        \n",
    "        init = tf.initialize_all_variables()\n",
    "    \n",
    "    with tf.Session(graph=graph) as session:\n",
    "        \n",
    "        init.run()\n",
    "        print(\"Initialized\")\n",
    "        #saver = tf.train.Saver({'In'})\n",
    "        \n",
    "        average_loss = 0\n",
    "        for step in xrange(num_steps):\n",
    "            batch_inputs, batch_labels = gen_batch(\n",
    "                data, batch_size, skip_window, num_skips)\n",
    "            feed_dict = {train_inputs : batch_inputs, \n",
    "                         train_labels : batch_labels}\n",
    "            \n",
    "            _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "            average_loss += loss_val\n",
    "\n",
    "        \n",
    "            if step % 2000 == 0:\n",
    "                if step > 0:\n",
    "                    average_loss /= 2000\n",
    "                # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "                print(\"Average loss at step \", step, \": \", average_loss)\n",
    "                average_loss = 0\n",
    "\n",
    "            # Note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "            if step % 10000 == 0 and step > 0:\n",
    "                sim = similarity.eval()\n",
    "                for i in xrange(valid_size):\n",
    "                    valid_word = revdic[valid_examples[i]]\n",
    "                    top_k = 8 # number of nearest neighbors\n",
    "                    nearest = (-sim[i, :]).argsort()[1:top_k+1]\n",
    "                    log_str = \"Nearest to %s:\" % valid_word\n",
    "                    for k in xrange(top_k):\n",
    "                        close_word = revdic[nearest[k]]\n",
    "                        log_str = \"%s %s,\" % (log_str, close_word)\n",
    "                    print(log_str)\n",
    "\n",
    "        final_embeddings = normalized_embeddings.eval()\n",
    "        return final_embeddings\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KB = nx.read_gpickle('./KB1.gpickle')\n",
    "embeddings = np.load('./embedL!.npy')\n",
    "words = np.load('./words.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = np.array(list(filter(lambda word: word == \n",
    "                              str(KB.node[word]['number']), words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = np.load('./words.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev = 0\n",
    "\n",
    "#words = load()\n",
    "#KB = prep_graph(words)\n",
    "number_words = KB.number_of_nodes()\n",
    "batch_size = 256\n",
    "embedding_size = 200  # Dimension of the embedding vector.\n",
    "skip_window = 3      # How many words to consider left and right.\n",
    "num_skips = 4         # How many times to reuse an input to generate a label.\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors. Here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent.\n",
    "valid_size = 200    # Random set of words to evaluate similarity on.\n",
    "valid_window = number_words  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "num_sampled = 100    # Number of negative examples to sample.\n",
    "num_steps = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1349: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  distances = np.zeros(self.batch_size, dtype=X.dtype)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1360: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  validation_indices = random_state.randint(0, n_samples, init_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:671: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  init_indices = random_state.randint(0, n_samples, init_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1409: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  0, n_samples, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1465: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.cluster_centers_) for s in slices]\n"
     ]
    }
   ],
   "source": [
    "words_n = words[300000:]\n",
    "words_n, KB = add_level(words_n, embeddings, KB, 100)\n",
    "vocab_size = KB.number_of_nodes()\n",
    "revdic = {node[1]['number']: node[0] for node in KB.nodes(True)}\n",
    "data = [KB.node[word]['number'] for word in words_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27463\n",
      "Initialized\n",
      "Average loss at step  0 :  380.980895996\n",
      "Average loss at step  2000 :  79.8111888482\n",
      "Average loss at step  4000 :  15.5493148435\n",
      "Average loss at step  6000 :  6.42140151476\n",
      "Average loss at step  8000 :  2.97634607694\n",
      "Average loss at step  10000 :  1.60695872615\n",
      "Nearest to 14863: 20264, 20916, 14179, Was, 16821, 13287, uncompanionable, 23272,\n",
      "Nearest to 14348: 25196, slacken, 10278, fine, join, hedges, 25765, 26309,\n",
      "Nearest to flew: 12461, 12966, unworthy, 18113, Reflection, shouted, opposed, inspired,\n",
      "Nearest to 11133: circles, subjects, 18110, 15153, 12230, 23534, 24199, disposing,\n",
      "Nearest to 18918: croqueted, 8877, 15106, 11336, 19823, 16106, 15974, 18765,\n",
      "Nearest to retailing: 26240, 17225, 13051, 21973, 22488, 25319, 17232, 23307,\n",
      "Nearest to 26663: name, 10017, instinctively, 16964, height, 24132, 12401, yawned,\n",
      "Nearest to 15181: 20001, 15275, 13792, 11383, 27243, 25988, 18342, 27169,\n",
      "Nearest to 16104: 21721, 14037, 26969, 14461, 14260, 14066, 26194, 14445,\n",
      "Nearest to wonders: 11400, 8615, 13070, 15206, 14900, 21155, Hjckrrh, 9075,\n",
      "Nearest to 27340: 25988, 15380, 18756, 26850, 21990, 18102, 18467, 18342,\n",
      "Nearest to 26846: 17661, 26129, 17906, 23551, arch, 22416, 21456, 25643,\n",
      "Nearest to interrupting: 16411, 11952, 9552, bitterness, 20871, 21290, 27209, 21671,\n",
      "Nearest to interest: Bennet, 13121, diffident, 21422, 9477, 9270, 27427, 22271,\n",
      "Nearest to @: 21454, em, 17963, attitude, presuming, 25620, agitation, brought,\n",
      "Nearest to 25456: 20528, overpower, 13994, 8828, 15111, prudent, LL, 18788,\n",
      "Nearest to 9898: 15702, pleasantry, 13255, 18091, 11822, 24700, undertone, 19941,\n",
      "Nearest to banished: Ma, station, 24577, shrink, 24733, 22949, 10321, angry,\n",
      "Nearest to rebuke: 9597, 13285, 13086, giddy, 20020, worm, 24858, 15170,\n",
      "Nearest to 15830: 15380, 25988, 19682, 19091, 11598, 13275, 24166, 13166,\n",
      "Nearest to 18203: 18380, 9089, 13275, 19091, 13230, 19113, 10438, 14066,\n",
      "Nearest to 14725: 22691, 12187, 23687, inconvenient, 11979, 26262, 20843, tipped,\n",
      "Nearest to repelled: 14459, 26004, deeply, 16892, 22697, 9212, Again, 20379,\n",
      "Nearest to 20569: 16682, 17483, 13948, 26296, 17467, Before, 13989, 24200,\n",
      "Nearest to 11776: 20964, 23100, proprietor, 23251, 11023, 19556, 10488, 11381,\n",
      "Nearest to 27293: 23051, 20751, 15527, 23471, angry, 26755, 15385, cauldron,\n",
      "Nearest to 15456: 9060, 21329, 20171, 23860, 13449, 22179, 16512, fishing,\n",
      "Nearest to 22300: 8582, gallant, 26243, 16461, lazily, 22649, 15886, 15763,\n",
      "Nearest to .’”: 14223, 18031, 19606, 16103, 26731, 25207, 11854, noticed,\n",
      "Nearest to 14159: 24725, affording, 13128, Implacable, 25384, 10810, 20327, 18599,\n",
      "Nearest to 21170: 21819, marriage, 17656, _her_, 20571, 16144, 25619, 10321,\n",
      "Nearest to 21081: 23180, 8995, 14860, 13164, 9381, unaccountable, 21153, 25618,\n",
      "Nearest to 11741: out_, 25036, 11115, 21664, 13632, care, roses, 11306,\n",
      "Nearest to 21294: let, 15134, 25574, Mind, tranquil, 25655, 21341, stared,\n",
      "Nearest to tired: nor, deliberation, 16621, Always, 25011, scruple, promoting, 23666,\n",
      "Nearest to 21109: 13621, 24125, 9030, 20888, 14020, ringlets, displease, splendour,\n",
      "Nearest to 26339: impulse, slit, reader, 11256, 27220, 20675, 9399, found,\n",
      "Nearest to 20432: management, succeeded, 21357, injuries, 9800, 26691, 13005, 16293,\n",
      "Nearest to 12895: 11408, 10330, 25537, 23659, nine, Clement, instead, 21725,\n",
      "Nearest to 19283: 13275, 13157, 25088, 9116, 19007, 25988, 20421, 19091,\n",
      "Nearest to whereupon: 11339, 14781, 25942, 19439, 17072, 20993, 23127, 11995,\n",
      "Nearest to cooking: cried, lead, 24341, 23965, 25941, 10964, intimacy, 12854,\n",
      "Nearest to 10045: insolence, 14300, 15802, 11675, industriously, 23800, grievances, 24019,\n",
      "Nearest to captivated: learned, 18729, 12908, flung, vain, 16763, 19747, 24205,\n",
      "Nearest to whiting: 16921, ”--, 22356, 21604, 16487, knuckles, 23137, expences,\n",
      "Nearest to 21341: 35, 22866, 25625, 19286, desired, arrested, or, 24521,\n",
      "Nearest to wow: 24850, 25175, 19807, 26573, 18184, transpired, unforgiving, 16272,\n",
      "Nearest to 12088: 18996, thoughtlessness, fate, 15487, ragout, 10287, 26695, Charles,\n",
      "Nearest to 14767: 23275, afore, Mabel, 21842, 26614, 21313, 25230, guests,\n",
      "Nearest to 20269: 10630, 17300, 16432, _another, 12196, 25553, 22837, 24935,\n",
      "Nearest to 24170: _as, 11482, 15868, 14218, 27091, 12539, 27437, 25541,\n",
      "Nearest to 21594: deeper, 26810, convinced, guessed, travellers, 24346, 12382, 23802,\n",
      "Nearest to 22933: daughter, 23646, 27100, 23212, reminding, 21200, 13780, solemn,\n",
      "Nearest to 18263: archness, plainer, 24074, unlink, 9875, MY, 10920, 18991,\n",
      "Nearest to 11223: 12648, 25416, 24804, 13688, additional, 21794, 17307, relate,\n",
      "Nearest to 9121: 9326, 9318, 15380, 17799, 18353, 15631, 17412, 17776,\n",
      "Nearest to knot: 18272, 20681, 22459, 15278, 19755, 21016, 10309, identification,\n",
      "Nearest to 27022: portrait, 14563, moreover, 17640, 14351, 21800, 8877, elegance,\n",
      "Nearest to 25011: 15833, exchanged, 13516, 17735, tired, 18797, 11723, 23604,\n",
      "Nearest to 25789: 11200, 11594, 22914, 9875, jealousy, 21234, learnt, declaration,\n",
      "Nearest to 15230: 10702, _have_, February, 9393, 10996, willingness, 26864, truest,\n",
      "Nearest to 17074: SOMETHING, 8564, 15702, 19104, whispers, keenest, 25698, 23449,\n",
      "Nearest to 9684: 13773, 25648, inspired, 21191, blemish, 22932, tied, disagreeable,\n",
      "Nearest to 12246: 10618, 16265, 10543, 21728, AGREEMENT, paper, 12564, d,\n",
      "Nearest to 11786: 17739, 15656, 25988, 16233, 9315, 15829, 21721, 17737,\n",
      "Nearest to creature: 16830, 19774, 20587, expostulation, situated, 11136, 16895, filial,\n",
      "Nearest to 19214: 25707, 13110, 14171, 12449, 26175, 9248, 9019, formation,\n",
      "Nearest to 24579: 9586, confident, 16064, 26571, bring, 12855, 24375, 9370,\n",
      "Nearest to 11554: 11252, 4557, Digging, disinclined, 16767, 22715, 19174, _very_,\n",
      "Nearest to 17833: 24117, 12819, 18898, org, 20701, 12387, 13564, 14798,\n",
      "Nearest to 26205: 12889, 14100, prettyish, 11002, 26390, 9724, 14989, 24921,\n",
      "Nearest to 21075: 23869, 13507, mess, blameable, 26382, 11167, affectation, 15769,\n",
      "Nearest to 15256: All, 26173, 26783, 19384, terrific, 8858, 20904, cover,\n",
      "Nearest to cooks: dishonourable, 21472, 16604, Take, 23895, _violent, 9648, nose,\n",
      "Nearest to 14600: 20404, 10646, gowns, subsist, August, 17242, 18923, 19692,\n",
      "Nearest to 27256: waving, 12949, trimming, 11476, disliking, 15657, 9851, 20061,\n",
      "Nearest to 21202: 19091, 27366, 27155, 25988, 13275, 27119, 21721, 15380,\n",
      "Nearest to 26808: 16760, 19290, 16820, 27430, 18837, 12158, 11074, 19682,\n",
      "Nearest to 14720: 25193, apologised, best, 12428, 13643, uniformity, engaging, hatefully,\n",
      "Nearest to 10168: 22080, 24593, 13453, hundred, suspend, 23720, governed, 24304,\n",
      "Nearest to 25054: 17421, 12477, 23135, 11203, intentionally, 16983, 15996, 26957,\n",
      "Nearest to contrivance: blots, puzzling, 14988, 22377, 23173, 14060, morrow, 19582,\n",
      "Nearest to vogue: 19454, sweetness, 19213, 18621, 11168, 15043, 24213, 8650,\n",
      "Nearest to 20767: 11641, commonly, 26774, local, 16519, mark, 10515, 18536,\n",
      "Nearest to 13961: 25496, 23720, _should_, 23550, 24430, flirt, realised, 13723,\n",
      "Nearest to 13720: coincide, 22944, elegant, 13552, 10938, 14366, 24579, 26055,\n",
      "Nearest to rose: 23087, 16122, Three, 11713, already, 8590, 12561, restless,\n",
      "Nearest to decent: 26472, sentiments, 23499, can, 10521, 12319, 24505, serpents,\n",
      "Nearest to liked: 16929, 10742, recovered, 12449, 8607, 15365, lieutenant, bowed,\n",
      "Nearest to 13878: 26035, 26183, 12558, 27358, rein, costs, 22316, chose,\n",
      "Nearest to despise: bearing, SEND, 9318, ceased, 27013, 20319, shaking, 24006,\n",
      "Nearest to 24498: dined, 9688, 19966, 24104, abundant, 11812, 13853, 16953,\n",
      "Nearest to 11375: damp, Redistributing, curtsey, endure, 22144, impatiently, 22695, 19060,\n",
      "Nearest to evenness: wonderfully, liability, 18248, THEY, independence, 24312, 10641, 23303,\n",
      "Nearest to 25254: 19731, 21335, arms, Pemberley, overcome, 13241, 21106, 26431,\n",
      "Nearest to Turtle: 27251, 15306, preparing, 14226, 17146, 22900, 26649, 13549,\n",
      "Nearest to 20064: 11489, 17415, 16705, 9773, 9401, 17676, 9089, 8996,\n",
      "Nearest to GARDINER: 24881, footman, 19558, 20728, coward, 18707, Imprudence, 10388,\n",
      "Nearest to telescope: 16597, 25862, 22594, vulgarity, 14681, 24668, hair, 17141,\n",
      "Nearest to 13296: spars, quarrelled, 22836, 17266, 9586, ADVENTURES, 24141, 20888,\n",
      "Nearest to 20232: 27243, 14572, 15380, 18975, 18621, 19267, 19666, 15886,\n",
      "Nearest to proportion: said, 10322, 27349, 22072, proves, genius, 25255, inconveniences,\n",
      "Nearest to 19380: prospects, 22319, 23072, Maybe, notions, 21463, 24656, wonderfully,\n",
      "Nearest to 14919: 10102, 20125, 19013, 12854, 23200, 10439, 10534, Harriet,\n",
      "Nearest to balanced: 21898, 13849, 23926, 9848, wants, 21711, felt, 25347,\n",
      "Nearest to 11781: 9476, 10473, 23058, meekly, 1887, 21007, 24419, 24241,\n",
      "Nearest to 16562: 26130, 16563, 15393, 25988, 12300, 26850, 18692, 14109,\n",
      "Nearest to condescended: 19813, 13898, 12320, 20650, 17988, 19411, 9256, smiling,\n",
      "Nearest to 16912: dictatorial, independent, 11693, 11482, 13333, 12280, employment, 25790,\n",
      "Nearest to 11894: 20756, 12255, 21721, 24166, 17691, 25988, 19639, 18756,\n",
      "Nearest to beautifully: 9506, heinous, 26173, 18461, secrecy, parental, 13439, 13676,\n",
      "Nearest to cackled: 11174, 18184, 15016, ring, producing, 16114, 25661, 9786,\n",
      "Nearest to 22779: 15397, 22123, 24802, 15725, 20856, resigned, 14284, 22518,\n",
      "Nearest to 27254: 14923, AGREE, 10898, 23779, 9322, 17331, 24623, 23249,\n",
      "Nearest to 21642: dreaded, Melan, 21021, 20515, 12702, fighting, contrariety, 13955,\n",
      "Nearest to 23365: contrariwise, unwelcome, grins, troublesome, Majesty, 16955, 18490, 23830,\n",
      "Nearest to 26127: 22638, tails, 23817, 27227, 10400, 24001, 26024, 26465,\n",
      "Nearest to 11765: secured, 21492, 25992, 24693, archly, 18504, 26993, 19807,\n",
      "Nearest to 13840: 9840, 12437, 13459, 16080, 11044, 22139, immense, 11647,\n",
      "Nearest to _laugh_: 12493, reality, 26614, 11570, painter, 14987, 26115, 14611,\n",
      "Nearest to Lakes: scrupled, discomposed, 19123, 30, 22454, 12913, 10771, Herald,\n",
      "Nearest to 25087: tiptoe, 9989, 21519, 11236, 26423, falls, 15696, blasted,\n",
      "Nearest to playful: 21685, retire, appearances, ALL, haughty, 16969, 16552, 21224,\n",
      "Nearest to 16904: 10826, 14667, 16815, sincerity, 11469, I, 9948, 12516,\n",
      "Nearest to feeble: perseverance, 12782, 11438, 26730, Dear, additional, dose, opening,\n",
      "Nearest to 14660: Unfortunately, holder, 24598, 20630, expectation, 15165, 23883, lamenting,\n",
      "Nearest to 16745: grown, possessed, 15837, 15093, 26545, 26865, 14158, 9208,\n",
      "Nearest to 27384: 16509, 19457, 8682, 19613, 14942, 19647, 18467, 18331,\n",
      "Nearest to breeze: 12669, Mine, 13449, 25669, 22145, 18318, 11555, 25273,\n",
      "Nearest to 12475: 14210, Rosings, 21914, 14178, 21796, 12058, driven, Coming,\n",
      "Nearest to 10476: acquire, 11810, payment, 10285, infliction, 23677, 14890, 11019,\n",
      "Nearest to 21867: downstairs, 9768, 17135, 15979, 14854, wanting, 15638, 14882,\n",
      "Nearest to 24984: 16855, 9685, 26606, 23981, 21961, 22943, MYSELF, 15586,\n",
      "Nearest to due: binary, 25937, don, 22092, names, 26622, sobbing, 14519,\n",
      "Nearest to Assistance: 17687, wishes, tortured, 27135, enumeration, 16635, 9196, 10184,\n",
      "Nearest to happiness: 17294, 19876, 10732, 16724, 18783, 22197, dry, 26949,\n",
      "Nearest to 18170: 18031, sonnet, started, 16810, 12992, griefs, 16396, 11356,\n",
      "Nearest to 26762: consigned, 16057, 19995, purport, 10466, 25580, 22205, affairs,\n",
      "Nearest to 10256: 24985, 19924, warn, 22445, 13758, cautioning, 19957, expressive,\n",
      "Nearest to hearty: 18633, trade, 14296, 8729, 15053, 19829, crushing, silence,\n",
      "Nearest to has: 19561, 25738, 21817, 11537, 20369, 19070, 10377, 16299,\n",
      "Nearest to persuaded: 24335, 25304, object, 12770, 18283, humiliation, 22821, 23400,\n",
      "Nearest to 25907: fright, 17758, 15672, talked, assert, 16183, 19336, 21474,\n",
      "Nearest to 12979: 19689, 17554, 20419, 15178, 17639, 19237, 8805, 9090,\n",
      "Nearest to undertaken: 16520, pretension, envying, 25881, 26809, 24436, 13378, 11519,\n",
      "Nearest to 9766: 26800, 17769, 25988, 18692, 27186, 26328, 13275, 19091,\n",
      "Nearest to borne: 12004, drove, 24720, 14567, 14640, 11399, 12968, 8797,\n",
      "Nearest to coat: 21348, innocent, 11479, 12097, rested, beauteous, 13024, 23354,\n",
      "Nearest to 17404: busy, marriage, 13985, 23880, License, 12312, 21978, 14917,\n",
      "Nearest to deliberately: almost, 10864, 13355, 25580, excuse, 15100, 8581, 25241,\n",
      "Nearest to pinch: 27441, 19589, 22511, 18830, 20279, 19390, 8810, 8844,\n",
      "Nearest to 16168: 19617, 27155, 16324, 21990, 13157, 25988, 19091, 26328,\n",
      "Nearest to 15529: 17757, forty, 25035, 13523, EVERYBODY, 26617, 16296, heedless,\n",
      "Nearest to visitor: 11022, wavering, kill, 21691, subscribe, 13467, friends, Eastbourne,\n",
      "Nearest to 18773: face, 16027, somewhat, 20642, 16289, objects, 25548, 24588,\n",
      "Nearest to 11198: negative, 20659, 10612, 22701, 23005, 26560, 24035, 14819,\n",
      "Nearest to 18475: 20007, 21721, 20372, 17595, 14027, 16845, 20464, 13232,\n",
      "Nearest to 8859: 27185, 16253, 20547, 19091, 21721, 16563, 17691, 18692,\n",
      "Nearest to 11136: 21202, 18971, 17024, 11050, 9197, 27119, 8777, 18756,\n",
      "Nearest to clearing: 15497, 25219, pollution, 24594, 12764, 10843, 23050, 23022,\n",
      "Nearest to gay: Seriously, 13100, 14470, 19089, 22347, 15618, dissuaded, 19657,\n",
      "Nearest to sallied: performs, 19244, scrape, 22995, 14659, 26035, 26239, shrieked,\n",
      "Nearest to scrupulous: 12069, burying, indelicate, 10511, Dawson, 20307, unhappy, 10593,\n",
      "Nearest to 27310: 13157, 19682, 18756, 18396, 25988, 26060, 21721, 20068,\n",
      "Nearest to 26196: 18855, 18409, 20633, favourites, 10739, 23070, 27108, _appearance_,\n",
      "Nearest to 15362: pride, 24621, 20728, 22600, 9192, 16883, _endeavour_, 26848,\n",
      "Nearest to 27436: 27120, 20068, 17691, 27366, 19682, 19091, 27014, 24491,\n",
      "Nearest to 22184: apprehension, undoing, 11517, 21415, 11978, upper, 20678, None,\n",
      "Nearest to 10792: experiment, 10973, secrets, 17594, 12538, 22280, 24891, 25193,\n",
      "Nearest to confederacy: 16950, throw, 22277, 12043, 26671, 24270, bribery, 13880,\n",
      "Nearest to stupidity: 12460, 14058, 25236, cried, P, 13779, 19996, emphatic,\n",
      "Nearest to duck: 21742, 26355, 19200, 24828, 26138, 25025, 23217, 10612,\n",
      "Nearest to 19092: 9726, 25171, volunteers, 11896, accede, 19888, concurrence, 20749,\n",
      "Nearest to buttons: 19374, 20182, 16347, 16941, 27207, 26572, fanned, liked,\n",
      "Nearest to 23469: 17153, 22392, provoked, warmly, generously, 20765, healthful, 27036,\n",
      "Nearest to 10455: 26099, complexion, 13096, capable, 11299, 9063, 18585, moon,\n",
      "Nearest to 25051: 27330, 17034, 12218, intimation, 26957, 23496, give, 14385,\n",
      "Nearest to suffer: 11531, 27215, 12000, 22563, 15220, 13041, Once, 10167,\n",
      "Nearest to 23969: 21408, 23545, 10937, 12598, 15110, mistakes, 21207, 13584,\n",
      "Nearest to 8629: 12550, 10171, 17244, 27331, 12380, 20769, 10530, 9569,\n",
      "Nearest to 24226: 8580, 9214, 14784, gallantry, 22067, 14867, 10523, 17159,\n",
      "Nearest to 8698: 13866, 14297, 10770, 22173, 13879, 19091, 27366, 16433,\n",
      "Nearest to hearing: employments, Stuff, self, FULL, trespass, 22381, solemnity, rescue,\n",
      "Nearest to 17364: quiver, 16644, 15249, 19243, 14880, 24380, 19741, 13780,\n",
      "Nearest to 9838: 11633, 8568, 18811, 18995, 19637, 10170, 18337, 15651,\n",
      "Nearest to 11955: rapidity, 26493, 25278, 8837, 12269, 27153, 18771, insists,\n",
      "Nearest to 18272: 24166, 16563, 11221, 26501, 10746, 25299, 15380, 19274,\n",
      "Nearest to 22449: often, 11219, 12666, Sections, shame, 24896, 23768, addressed,\n",
      "Nearest to 10416: 26622, 25010, 18508, 10101, 25410, village, 26650, 21427,\n",
      "Nearest to 17221: unfolding, 23752, 20255, closure, risen, accuracy, 10819, defect,\n",
      "Nearest to 19005: 20375, 20204, 24263, 24238, 11481, 18822, 10674, afforded,\n",
      "Nearest to 19560: 14804, grievously, 17154, hoped, 10378, seconded, 19745, Pool,\n",
      "Nearest to 26403: 9222, importance, 26376, 18481, 12128, 20492, 26485, 16035,\n",
      "Nearest to 18398: chamber, sixth, 24096, 13306, 10939, 24267, 22570, testifying,\n",
      "Nearest to article: 21392, 24471, circumspect, Their, 23812, 26135, outlived, included,\n",
      "Nearest to 24151: 11442, rail, 9578, 19802, 16227, 26211, arrange, despicable,\n",
      "Nearest to 19438: 25988, 9089, 20196, 9407, 13792, 19091, 21202, 26818,\n",
      "Nearest to 22825: asperity, 18029, 26572, noble, applies, 21740, usually, 23763,\n",
      "Nearest to 23005: 13490, 18823, 8692, 27375, 18961, 17960, 13863, 13888,\n",
      "Nearest to 13547: 19640, Chapter, 21489, 17238, 26222, detail, 27031, 17431,\n",
      "Average loss at step  12000 :  1.45913607972\n",
      "Average loss at step  14000 :  1.80266628453\n",
      "Average loss at step  16000 :  1.36668225223\n",
      "Average loss at step  18000 :  1.26659178106\n",
      "Average loss at step  20000 :  1.33625019673\n",
      "Nearest to 14863: 20264, 20916, 14179, Was, 16821, 13287, uncompanionable, 23272,\n",
      "Nearest to 14348: 25196, slacken, 10278, fine, join, hedges, 25765, 26309,\n",
      "Nearest to flew: 12461, 12966, unworthy, 18113, Reflection, shouted, opposed, 8600,\n",
      "Nearest to 11133: circles, subjects, 18110, 15153, 12230, 23534, 24199, disposing,\n",
      "Nearest to 18918: croqueted, 8877, 15106, 11336, 19823, 16106, 15974, 18765,\n",
      "Nearest to retailing: 26240, 17225, 13051, 21973, 22488, 25319, 17232, 23307,\n",
      "Nearest to 26663: name, 10017, instinctively, 16964, height, 24132, 12401, yawned,\n",
      "Nearest to 15181: 15275, 20001, 13792, 11383, 27243, 25988, 18342, 27169,\n",
      "Nearest to 16104: 21721, 26969, 14037, 14461, 26194, 14066, 16994, 14260,\n",
      "Nearest to wonders: 11400, 8615, 13070, 15206, 21155, 14900, Hjckrrh, 9075,\n",
      "Nearest to 27340: 25988, 26850, 15380, 18756, 21990, 18342, 18467, 18102,\n",
      "Nearest to 26846: 17661, 26129, 17906, 23551, arch, 22416, 21456, 25643,\n",
      "Nearest to interrupting: 16411, 11952, 9552, bitterness, 20871, 21290, 27209, 21671,\n",
      "Nearest to interest: Bennet, 13121, diffident, 21422, 9477, 9270, 27427, 22271,\n",
      "Nearest to @: 21454, em, 17963, attitude, presuming, 25620, agitation, brought,\n",
      "Nearest to 25456: 20528, overpower, 13994, 8828, 15111, prudent, LL, 18788,\n",
      "Nearest to 9898: 15702, pleasantry, 13255, 18091, 11822, 24700, undertone, 19941,\n",
      "Nearest to banished: Ma, station, 24577, shrink, 24733, 22949, 10321, angry,\n",
      "Nearest to rebuke: 9597, 13285, 13086, giddy, worm, 20020, 24858, 15170,\n",
      "Nearest to 15830: 15380, 25988, 19682, 19091, 11598, 17579, 24166, 13275,\n",
      "Nearest to 18203: 18380, 13275, 19091, 13230, 9089, 24166, 14066, 10438,\n",
      "Nearest to 14725: 22691, 12187, 23687, inconvenient, 11979, 26262, 20843, tipped,\n",
      "Nearest to repelled: 14459, 26004, deeply, 22697, 16892, 9212, Again, 20379,\n",
      "Nearest to 20569: 16682, 17483, 13948, 26296, 17467, Before, 13989, 24200,\n",
      "Nearest to 11776: 20964, 23100, proprietor, 23251, 11023, 19556, 10488, 11381,\n",
      "Nearest to 27293: 23051, 20751, 15527, 23471, angry, 15385, 26755, cauldron,\n",
      "Nearest to 15456: 9060, 21329, 20171, 23860, 13449, 22179, 16512, fishing,\n",
      "Nearest to 22300: 8582, gallant, 26243, 16461, lazily, 22649, 15886, 15763,\n",
      "Nearest to .’”: 14223, 18031, 19606, 16103, 26731, 25207, 11854, noticed,\n",
      "Nearest to 14159: 24725, affording, 13128, Implacable, 25384, 10810, 18599, 20327,\n",
      "Nearest to 21170: 21819, marriage, 17656, _her_, 20571, 16144, 25619, 10321,\n",
      "Nearest to 21081: 23180, 8995, 14860, 13164, 9381, unaccountable, 21153, 18404,\n",
      "Nearest to 11741: out_, 25036, 11115, 21664, 13632, care, roses, 11306,\n",
      "Nearest to 21294: let, 15134, 25574, Mind, tranquil, 25655, 21341, stared,\n",
      "Nearest to tired: nor, deliberation, 16621, Always, 25011, scruple, promoting, 23666,\n",
      "Nearest to 21109: 13621, 24125, 9030, 20888, 14020, ringlets, displease, splendour,\n",
      "Nearest to 26339: impulse, slit, reader, 11256, 27220, 20675, 9399, found,\n",
      "Nearest to 20432: management, succeeded, 21357, injuries, 9800, 26691, 13005, 14881,\n",
      "Nearest to 12895: 11408, 10330, 25537, 23659, nine, Clement, instead, 21725,\n",
      "Nearest to 19283: 13275, 13157, 25088, 25988, 9116, 19007, 19091, 27243,\n",
      "Nearest to whereupon: 11339, 14781, 25942, 19439, 20993, 17072, 23127, 11995,\n",
      "Nearest to cooking: cried, lead, 24341, 23965, 25941, 10964, intimacy, 12854,\n",
      "Nearest to 10045: insolence, 14300, 15802, 11675, industriously, 23800, grievances, 24019,\n",
      "Nearest to captivated: learned, 18729, 12908, flung, vain, 19747, 16763, 18829,\n",
      "Nearest to whiting: 16921, ”--, 22356, 21604, 16487, knuckles, 23137, expences,\n",
      "Nearest to 21341: 35, 22866, 25625, 19286, desired, arrested, or, 24521,\n",
      "Nearest to wow: 24850, 25175, 26573, 19807, 18184, transpired, unforgiving, 16272,\n",
      "Nearest to 12088: 18996, thoughtlessness, fate, 15487, ragout, 10287, 26695, Charles,\n",
      "Nearest to 14767: 23275, afore, Mabel, 21842, 26614, 21313, 25230, guests,\n",
      "Nearest to 20269: 10630, 17300, 16432, _another, 12196, 25553, 22837, 24935,\n",
      "Nearest to 24170: _as, 11482, 15868, 14218, 27091, 12539, 25541, Hurst,\n",
      "Nearest to 21594: deeper, 26810, convinced, guessed, travellers, 24346, 12382, 23802,\n",
      "Nearest to 22933: daughter, 23646, 27100, 23212, reminding, 21200, 13780, solemn,\n",
      "Nearest to 18263: archness, plainer, 24074, unlink, 9875, MY, 10920, 18991,\n",
      "Nearest to 11223: 12648, 25416, 24804, 13688, additional, 21794, 17307, relate,\n",
      "Nearest to 9121: 9326, 17799, 9318, 15380, 18353, 15631, 17776, 17412,\n",
      "Nearest to knot: 20681, 18272, 22459, 15278, 21016, 10309, identification, 25968,\n",
      "Nearest to 27022: portrait, 14563, moreover, 17640, 14351, 21800, 8877, elegance,\n",
      "Nearest to 25011: 15833, exchanged, 13516, 17735, tired, 18797, 11723, 23604,\n",
      "Nearest to 25789: 11200, 11594, 22914, 9875, jealousy, 21234, learnt, declaration,\n",
      "Nearest to 15230: 10702, _have_, February, 9393, 10996, willingness, 26864, truest,\n",
      "Nearest to 17074: SOMETHING, 8564, 15702, 19104, whispers, keenest, 25698, 23449,\n",
      "Nearest to 9684: 13773, 25648, inspired, 21191, blemish, 22932, tied, disagreeable,\n",
      "Nearest to 12246: 10618, 16265, 10543, 21728, AGREEMENT, paper, 12564, d,\n",
      "Nearest to 11786: 17739, 15656, 9315, 25988, 16233, 15829, 17737, 21721,\n",
      "Nearest to creature: 16830, 19774, 20587, expostulation, situated, 8956, 11136, 12379,\n",
      "Nearest to 19214: 13110, 25707, 14171, 12449, 26175, 9248, 9019, formation,\n",
      "Nearest to 24579: 9586, confident, 16064, 26571, bring, 12855, 24375, 9370,\n",
      "Nearest to 11554: 11252, 4557, Digging, disinclined, 16767, 22715, 19174, _very_,\n",
      "Nearest to 17833: 24117, 12819, 18898, org, 20701, 12387, 13564, 14798,\n",
      "Nearest to 26205: 12889, 14100, prettyish, 11002, 26390, 9724, 14989, 24921,\n",
      "Nearest to 21075: 23869, 13507, mess, blameable, 26382, 11167, affectation, 15769,\n",
      "Nearest to 15256: All, 26173, 26783, 19384, terrific, 8858, 20904, cover,\n",
      "Nearest to cooks: dishonourable, 21472, 16604, Take, 23895, _violent, 9648, nose,\n",
      "Nearest to 14600: 20404, 10646, gowns, subsist, August, 17242, 18923, 19692,\n",
      "Nearest to 27256: waving, 12949, trimming, 11476, disliking, 15657, 9851, 20061,\n",
      "Nearest to 21202: 19091, 27155, 25988, 27119, 21721, 13275, 15380, 26328,\n",
      "Nearest to 26808: 16760, 18837, 27430, 16820, 19290, 12158, 11074, 19682,\n",
      "Nearest to 14720: 25193, apologised, best, 12428, uniformity, engaging, 13643, hatefully,\n",
      "Nearest to 10168: 22080, 24593, 13453, hundred, suspend, 23720, governed, 24304,\n",
      "Nearest to 25054: 17421, 12477, 23135, 14974, 11203, intentionally, 16983, 15996,\n",
      "Nearest to contrivance: blots, puzzling, 14988, 22377, 23173, 14060, morrow, 19582,\n",
      "Nearest to vogue: 19454, sweetness, 19213, 18621, 11168, 15043, 24213, 8650,\n",
      "Nearest to 20767: 11641, commonly, 26774, local, 16519, mark, 18536, 10515,\n",
      "Nearest to 13961: 25496, 23720, _should_, 23550, 24430, flirt, realised, 13723,\n",
      "Nearest to 13720: coincide, 22944, elegant, 13552, 10938, 14366, 24579, 26055,\n",
      "Nearest to rose: 23087, 16122, Three, 11713, already, 8590, 12561, restless,\n",
      "Nearest to decent: 26472, sentiments, 23499, can, 10521, 12319, 24505, serpents,\n",
      "Nearest to liked: 16929, 10742, 8607, recovered, 12449, 15365, lieutenant, bowed,\n",
      "Nearest to 13878: 26035, 26183, 12558, 27358, rein, costs, 22316, chose,\n",
      "Nearest to despise: bearing, SEND, 9318, ceased, 27013, 20319, shaking, 24006,\n",
      "Nearest to 24498: dined, 9688, 24104, abundant, 11812, 19966, 13853, 16953,\n",
      "Nearest to 11375: damp, Redistributing, curtsey, endure, 22144, impatiently, 22695, 19060,\n",
      "Nearest to evenness: wonderfully, liability, 18248, THEY, independence, 24312, 10641, 23303,\n",
      "Nearest to 25254: 19731, 21335, arms, Pemberley, overcome, 13241, 21106, 26431,\n",
      "Nearest to Turtle: 27251, 15306, preparing, 14226, 17146, 22900, 26649, 13549,\n",
      "Nearest to 20064: 11489, 17415, 9773, 16705, 9401, 17676, 19091, 9594,\n",
      "Nearest to GARDINER: 24881, footman, 19558, 20728, coward, 18707, Imprudence, 10388,\n",
      "Nearest to telescope: 16597, 25862, 22594, vulgarity, 14681, 24668, hair, 17141,\n",
      "Nearest to 13296: spars, quarrelled, 22836, 17266, 9586, ADVENTURES, 24141, 20888,\n",
      "Nearest to 20232: 27243, 15380, 14572, 18975, 18621, 20132, 15886, 19666,\n",
      "Nearest to proportion: said, 10322, 27349, 22072, proves, genius, 25255, inconveniences,\n",
      "Nearest to 19380: prospects, 22319, 23072, Maybe, notions, 21463, 24656, wonderfully,\n",
      "Nearest to 14919: 10102, 20125, 19013, 12854, 23200, 10439, 10534, Harriet,\n",
      "Nearest to balanced: 21898, 23926, 9848, wants, 21711, felt, 25347, 13473,\n",
      "Nearest to 11781: 9476, 10473, 23058, meekly, 1887, 21007, 24419, 24241,\n",
      "Nearest to 16562: 26130, 15150, 15393, 16563, 12300, 25988, 14109, 17589,\n",
      "Nearest to condescended: 19813, 13898, 12320, 20650, 17988, 9256, 19411, 19755,\n",
      "Nearest to 16912: dictatorial, independent, 11693, 11482, 13333, 12280, employment, 25790,\n",
      "Nearest to 11894: 20756, 12255, 21721, 24166, 17691, 25988, 19639, 18756,\n",
      "Nearest to beautifully: 9506, heinous, 26173, 18461, secrecy, parental, 13439, 13676,\n",
      "Nearest to cackled: 11174, 18184, 15016, ring, producing, 16114, 25661, 9786,\n",
      "Nearest to 22779: 15397, 22123, 24802, 15725, 20856, resigned, 14284, 14307,\n",
      "Nearest to 27254: 14923, AGREE, 10898, 23779, 17331, 24623, 9322, 23249,\n",
      "Nearest to 21642: dreaded, Melan, 21021, 20515, 12702, fighting, contrariety, 13955,\n",
      "Nearest to 23365: contrariwise, unwelcome, grins, troublesome, Majesty, 16955, 18490, 23830,\n",
      "Nearest to 26127: 22638, tails, 23817, 27227, 10400, 24001, 26024, 26465,\n",
      "Nearest to 11765: secured, 21492, 25992, 24693, archly, 18504, 26993, 19807,\n",
      "Nearest to 13840: 9840, 12437, 13459, 16080, 11044, 22139, immense, 11647,\n",
      "Nearest to _laugh_: 12493, reality, 26614, 11570, painter, 14987, 26115, 14611,\n",
      "Nearest to Lakes: scrupled, discomposed, 19123, 30, 22454, 12913, 10771, Herald,\n",
      "Nearest to 25087: tiptoe, 9989, 21519, 11236, 26423, falls, 15696, blasted,\n",
      "Nearest to playful: 21685, retire, appearances, ALL, haughty, 16552, 16969, 21224,\n",
      "Nearest to 16904: 10826, 14667, 16815, sincerity, 11469, I, 9948, 12516,\n",
      "Nearest to feeble: perseverance, 12782, 11438, 26730, Dear, additional, dose, opening,\n",
      "Nearest to 14660: Unfortunately, holder, 24598, 20630, expectation, 15165, 23883, lamenting,\n",
      "Nearest to 16745: grown, possessed, 15837, 15093, 26545, 26865, 14158, 9208,\n",
      "Nearest to 27384: 16509, 14942, 19457, 19613, 18331, 18467, 19647, 8682,\n",
      "Nearest to breeze: 12669, Mine, 13449, 25669, 22145, 18318, 11555, 25273,\n",
      "Nearest to 12475: 16962, 9003, 20487, 20068, 8727, 17797, 8977, 17959,\n",
      "Nearest to 10476: acquire, 11810, payment, 10285, infliction, 23677, 14890, 11019,\n",
      "Nearest to 21867: downstairs, 9768, 17135, 15979, 14854, wanting, 19915, 14882,\n",
      "Nearest to 24984: 16855, 9685, 26606, 23981, 21961, 22943, MYSELF, 15586,\n",
      "Nearest to due: binary, 25937, don, 22092, names, 26622, sobbing, 14519,\n",
      "Nearest to Assistance: 17687, wishes, tortured, 27135, enumeration, 16635, 9196, 10184,\n",
      "Nearest to happiness: 17294, 19876, 10732, 16724, 18783, 22197, dry, 26949,\n",
      "Nearest to 18170: 18031, sonnet, started, 16810, 12992, griefs, 16396, 11356,\n",
      "Nearest to 26762: consigned, 16057, 19995, purport, 10466, 25580, 22205, affairs,\n",
      "Nearest to 10256: 24985, 19924, warn, 22445, 13758, cautioning, 19957, expressive,\n",
      "Nearest to hearty: 18633, trade, 14296, 8729, 15053, 19829, crushing, silence,\n",
      "Nearest to has: 19561, 25738, 21817, 11537, 20369, 19070, 10377, 27227,\n",
      "Nearest to persuaded: 24335, 25304, object, 12770, 18283, humiliation, 22821, 23400,\n",
      "Nearest to 25907: fright, 17758, 15672, talked, assert, 16183, 19336, 21474,\n",
      "Nearest to 12979: 19689, 17554, 15178, 20419, 17639, 12379, 25988, 19237,\n",
      "Nearest to undertaken: 16520, pretension, envying, 25881, 26809, 24436, 13378, 16848,\n",
      "Nearest to 9766: 26800, 17769, 25988, 8724, 18692, 27186, 26328, 14487,\n",
      "Nearest to borne: 12004, drove, 24720, 14567, 14640, 11399, 12968, 8797,\n",
      "Nearest to coat: 21348, innocent, 11479, 12097, rested, beauteous, 13024, 23354,\n",
      "Nearest to 17404: busy, marriage, 13985, 23880, License, 12312, 21978, 14917,\n",
      "Nearest to deliberately: almost, 10864, 13355, 25580, excuse, 15100, 8581, 25241,\n",
      "Nearest to pinch: 27441, 19589, 22511, 18830, 20279, 19390, 8810, 8844,\n",
      "Nearest to 16168: 19617, 27155, 21990, 16324, 13157, 25988, 19091, 26328,\n",
      "Nearest to 15529: 17757, forty, 25035, 13523, EVERYBODY, 26617, 16296, heedless,\n",
      "Nearest to visitor: 11022, wavering, kill, 21691, subscribe, 13467, friends, Eastbourne,\n",
      "Nearest to 18773: face, 16027, somewhat, 20642, 16289, objects, 25548, 24588,\n",
      "Nearest to 11198: negative, 20659, 10612, 22701, 23005, 26560, 24035, 14819,\n",
      "Nearest to 18475: 20007, 21721, 20372, 14027, 17595, 13232, 20030, 20464,\n",
      "Nearest to 8859: 27185, 16253, 20547, 27287, 19091, 21721, 16563, 17691,\n",
      "Nearest to 11136: 21202, 17024, 18971, 11050, 9197, 27119, 8777, 9797,\n",
      "Nearest to clearing: 15497, 25219, pollution, 24594, 12764, 10843, 23050, 23022,\n",
      "Nearest to gay: Seriously, 13100, 14470, 19089, 22347, 15618, dissuaded, 10203,\n",
      "Nearest to sallied: performs, 19244, scrape, 22995, 14659, 26035, 26239, shrieked,\n",
      "Nearest to scrupulous: 12069, burying, indelicate, 10511, 20307, Dawson, unhappy, 10593,\n",
      "Nearest to 27310: 27366, 13157, 25988, 18756, 21721, 19682, 15380, 27119,\n",
      "Nearest to 26196: 18409, 18855, 20633, favourites, 10739, 23070, _appearance_, 27108,\n",
      "Nearest to 15362: pride, 24621, 20728, 22600, 9192, 16883, _endeavour_, 26848,\n",
      "Nearest to 27436: 27120, 20068, 17691, 19682, 19091, 27014, 17412, 8889,\n",
      "Nearest to 22184: apprehension, undoing, 11517, 21415, 11978, upper, 20678, None,\n",
      "Nearest to 10792: experiment, 10973, secrets, 17594, 12538, 22280, 24891, 25193,\n",
      "Nearest to confederacy: 16950, throw, 22277, 12043, 26671, 24270, bribery, 13880,\n",
      "Nearest to stupidity: 12460, 14058, 25236, cried, P, 13779, 19996, emphatic,\n",
      "Nearest to duck: 21742, 26355, 19200, 24828, 26138, 25025, 23217, 10612,\n",
      "Nearest to 19092: 9726, 25171, volunteers, 11896, accede, 19888, concurrence, 20749,\n",
      "Nearest to buttons: 19374, 20182, 16347, 16941, 27207, 26572, fanned, liked,\n",
      "Nearest to 23469: 17153, 22392, provoked, warmly, generously, 20765, healthful, 27036,\n",
      "Nearest to 10455: 26099, complexion, 13096, capable, 11299, 9063, 18585, moon,\n",
      "Nearest to 25051: 27330, 17034, 12218, intimation, 26957, 23496, give, 14385,\n",
      "Nearest to suffer: 11531, 27215, 12000, 22563, 15220, 13041, Once, 10167,\n",
      "Nearest to 23969: 21408, 23545, 10937, 12598, 15110, mistakes, 21207, 13584,\n",
      "Nearest to 8629: 12550, 10171, 17244, 27331, 27462, 12380, 10530, 9569,\n",
      "Nearest to 24226: 8580, 9214, 14784, gallantry, 22067, 14867, 10523, 17159,\n",
      "Nearest to 8698: 13866, 22173, 10770, 14297, 16433, 27381, 19091, 13879,\n",
      "Nearest to hearing: employments, Stuff, self, FULL, trespass, 22381, solemnity, rescue,\n",
      "Nearest to 17364: quiver, 16644, 15249, 19243, 14880, 24380, 13780, 19741,\n",
      "Nearest to 9838: 11633, 8568, 18811, 10170, 19637, 18995, 18337, 15651,\n",
      "Nearest to 11955: rapidity, 26493, 25278, 8837, 12269, 27153, 18771, insists,\n",
      "Nearest to 18272: 24166, 16563, 10746, 11221, 26501, 27390, 25299, 15380,\n",
      "Nearest to 22449: often, 11219, 12666, Sections, shame, 24896, 23768, addressed,\n",
      "Nearest to 10416: 26622, 25010, 18508, 10101, 25410, village, 26650, 21427,\n",
      "Nearest to 17221: unfolding, 23752, closure, 20255, risen, accuracy, 10819, defect,\n",
      "Nearest to 19005: 20375, 24263, 24238, 20204, 11481, 18822, 10674, afforded,\n",
      "Nearest to 19560: 14804, grievously, 17154, hoped, 10378, seconded, 19745, Pool,\n",
      "Nearest to 26403: 9222, importance, 26376, 18481, 12128, 20492, 26485, 16035,\n",
      "Nearest to 18398: chamber, sixth, 24096, 13306, 10939, 24267, 22570, testifying,\n",
      "Nearest to article: 21392, 24471, circumspect, Their, 23812, 26135, outlived, included,\n",
      "Nearest to 24151: 11442, rail, 9578, 19802, 16227, 26211, arrange, despicable,\n",
      "Nearest to 19438: 25988, 9407, 20196, 13792, 21202, 19091, 26818, 19590,\n",
      "Nearest to 22825: asperity, 18029, 26572, noble, applies, 21740, usually, 23763,\n",
      "Nearest to 23005: 13490, 18823, 27375, 8692, 17960, 18961, 13888, 9074,\n",
      "Nearest to 13547: 19640, Chapter, 21489, 17238, 26222, detail, 27031, 17431,\n",
      "Average loss at step  22000 :  1.5464845821\n",
      "Average loss at step  24000 :  1.17818057983\n",
      "Average loss at step  26000 :  1.12688078333\n",
      "Average loss at step  28000 :  1.50367734729\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)\n",
    "valid_size = 200    # Random set of words to evaluate similarity on.\n",
    "valid_window = number_words  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "data_index = 0\n",
    "skip_window = 4\n",
    "embeddings = W2V(batch_size, embedding_size, skip_window,\n",
    "            num_skips, valid_size, valid_window,\n",
    "            valid_examples, num_sampled, vocab_size,\n",
    "            num_steps, data, revdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def par_words(words, KB):\n",
    "    for index, word in enumerate(words[:-1]):\n",
    "        if KB.has_node(word) and KB.has_node(words[index+1]):\n",
    "            if KB.has_edge(word, words[index+1]):\n",
    "                node_name = KB.edge[word][words[index+1]]['node']\n",
    "                words = np.insert(words, index+1, str(node_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.write_gpickle(KB, './KB2.gpickle')\n",
    "np.save('./embedL2!.npy', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('./words2.npy', words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TFKMC(vectors, n_clusters=1000, max_iter=100000):\n",
    "    mbatch = MiniBatchKMeans(n_clusters=n_clusters, batch_size=len(vectors)*.05, max_iter=max_iter)\n",
    "    centroids = mbatch.fit(vectors)\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read Gradient Descent Site\n",
    "### 2. Read the Candidate Sampling Thing\n",
    "### 3. Implement KMeans MiniBatch in TensorFlow\n",
    "### 4. Write Graph Adding Code\n",
    "### 5. Write Processing for Transitions into Graph\n",
    "### 6. Implement Word2Vec Using Graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
