{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import math\n",
    "from six.moves import xrange\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "class Infix(object):\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "    def __or__(self, other):\n",
    "        return self.func(other)\n",
    "    def __ror__(self, other):\n",
    "        return Infix(partial(self.func, other))\n",
    "    def __call__(self, v1, v2):\n",
    "        return self.func(v1, v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load():\n",
    "    ppp = nltk.data.load('../../Downloads/ppp.txt', encoding='utf8')\n",
    "    words_p = nltk.tokenize.wordpunct_tokenize(ppp)[130:]\n",
    "    alw = nltk.data.load('../../Downloads/alw.txt', encoding='utf8')\n",
    "    words_a = nltk.tokenize.wordpunct_tokenize(alw)[143:]\n",
    "    words = words_a + words_p\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn into list of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sentences(words):\n",
    "    sentences_word  = []\n",
    "    sent_word = []\n",
    "    for index, word in enumerate(words):\n",
    "        if word in ['?','.','!']:\n",
    "            sent_word += [word]\n",
    "            sentences_word += [sent_word]\n",
    "            sent_word = []\n",
    "        else:\n",
    "            sent_word += [word]\n",
    "    return sentences_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn Vocab into Indices\n",
    "-- This was process, but I think this is useful regardless. I will need to change it to accomodate ..... stuff?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(words, vocabulary_size):\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0  # dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Graph Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically we want to make sure that things are being added to the graph. How do we do this. Well. I think we should take them as if they were read in line and then only add things like that. This way we can do all our learning right good without having to stop and add to the graph\n",
    "\n",
    "Adding node likelihood : http://ieeexplore.ieee.org/document/7266560/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph(KB, embeddings, sentence, max_nodes):\n",
    "    def next_lvl(sentence):\n",
    "        @Infix\n",
    "        def to(a, b):\n",
    "            x = embeddings[sentence[b]] - embeddings[sentence[a]]\n",
    "            return x\n",
    "        \n",
    "        nl = []\n",
    "        ln = []\n",
    "        for index in range(len(sentence[:-1])):\n",
    "            if KB.has_edge(sentence[index], sentence[index+1]):\n",
    "                nl.append(KB[sentence[index]][sentence[index+1]]['node'])\n",
    "            else:\n",
    "                if KB.number_of_nodes()+1 < max_nodes:\n",
    "                    KB.add_node(KB.number_of_nodes(), exp=.5)\n",
    "                    KB.add_edge(sentence[index], sentence[index+1],\n",
    "                               node=KB.number_of_nodes())\n",
    "                    embeddings[KB.number_of_nodes()] = index |to| (index+1)\n",
    "                else:\n",
    "                    x = index |to| (index+1)\n",
    "                    similarity = cosine_similarity(embeddings, [x])\n",
    "                    nearest = np.argmax(similarity)\n",
    "                    exp = KB.node[nearest]['exp']\n",
    "                    embeddings[nearest] = embeddings[nearest]*exp + x*(1-exp)\n",
    "                    KB.node[nearest]['exp'] += (1-exp)**3\n",
    "                    if 1-similarity.max() > 1-exp:\n",
    "                        nl.append(nearest)\n",
    "                    \n",
    "                    if not KB.has_edge(sentence[index], sentence[index+1]):\n",
    "                        KB.add_edge(sentence[index], sentence[index+1], \n",
    "                                    node=nearest)\n",
    "        return nl\n",
    "    \n",
    "    \n",
    "    l_all = [sentence]\n",
    "    l_next = sentence\n",
    "    while l_next:\n",
    "        l_next = next_lvl(l_next)\n",
    "        print(l_next)\n",
    "        l_all += l_next\n",
    "    return KB, embeddings, l_all[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_graph(words):\n",
    "    KB2 = nx.Graph()\n",
    "    for word in words:\n",
    "        if not KB2.has_node(word):\n",
    "            KB2.add_node(word)\n",
    "        \n",
    "    KB3 = nx.convert_node_labels_to_integers(KB2, label_attribute='word')\n",
    "    KB4 = nx.Graph()\n",
    "    \n",
    "    for node in KB3.nodes(True):\n",
    "        KB4.add_node(node[1]['word'], number=node[0])\n",
    "    return KB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_level(words, embeddings, KB, n_cluster):\n",
    "    \n",
    "    for index, word in enumerate(words[:-1]):\n",
    "        if KB.has_node(word) and KB.has_node(words[index+1]):\n",
    "            if KB.has_edge(word, words[index+1]):\n",
    "                node_name = KB.edge[word][words[index+1]]['node']\n",
    "                words.insert(index+1, str(node_name))\n",
    "                \n",
    "    data = [KB.node[word]['number'] for word in words if word in KB.node]\n",
    "    \n",
    "    embed_data = np.array([embeddings[wordnum] for wordnum in data])\n",
    "    \n",
    "    next_lvl_raw = embed_data[1:] - embed_data[:-1]\n",
    "    next_lvl_cent = TFKMC(next_lvl_raw, n_clusters=n_cluster)\n",
    "\n",
    "    words_n = [words[0]]\n",
    "    vocab_size = KB.number_of_nodes()\n",
    "    \n",
    "    for num in range(vocab_size, vocab_size+n_cluster):\n",
    "        KB.add_node(str(num), number=num)\n",
    "    \n",
    "    for i in range(len(next_lvl_cent.labels_)):\n",
    "        t = next_lvl_cent.labels_[i]\n",
    "        words_n.extend([str(t+vocab_size), words[i+1]])\n",
    "        KB.add_edge(words[i], words[i+1], node=str(t+vocab_size))\n",
    "        \n",
    "    \n",
    "    \n",
    "    return words_n, KB     \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Each Batch\n",
    "-- a useful thing would be for batches to be made of few words, a couple sentences, and then be taken from there. idk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_index = 0\n",
    "def gen_batch(data, batch_size, skip_window, num_skips):\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1 # [ skip_window target skip_window ]\n",
    "    buffer = collections.deque(maxlen=span)\n",
    "    for _ in range(span):\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    for i in range(batch_size // num_skips):\n",
    "        target = skip_window  # target label at the center of the buffer\n",
    "        targets_to_avoid = [ skip_window ]\n",
    "        for j in range(num_skips):\n",
    "            while target in targets_to_avoid:\n",
    "                target = random.randint(0, span - 1)\n",
    "            targets_to_avoid.append(target)\n",
    "            batch[i * num_skips + j] = buffer[skip_window]\n",
    "            labels[i * num_skips + j, 0] = buffer[target]\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    return batch, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the Actual Word2Vec Algorithm in TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def W2V(batch_size, embedding_size, skip_window, num_skips, valid_size,\n",
    "       valid_window, valid_examples, num_sampled, vocabulary_size,\n",
    "       num_steps, data, revdic):\n",
    "    graph = tf.Graph()\n",
    "    \n",
    "    with graph.as_default():\n",
    "        train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "        train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "        valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "        \n",
    "        with tf.device('/cpu:0'):\n",
    "            \n",
    "            embeddings = tf.Variable(\n",
    "                            tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "            embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "        \n",
    "        nce_weights = tf.Variable(\n",
    "            tf.truncated_normal([vocabulary_size, embedding_size], \n",
    "                               stddev=1.0 / math.sqrt(embedding_size)))\n",
    "        nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "        \n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.nce_loss(nce_weights, nce_biases, embed, train_labels,\n",
    "                          num_sampled, vocabulary_size))\n",
    "        optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
    "        \n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), \n",
    "                                     1, keep_dims=True))\n",
    "        normalized_embeddings = embeddings / norm\n",
    "        valid_embeddings = tf.nn.embedding_lookup(\n",
    "            normalized_embeddings, valid_dataset)\n",
    "        similarity = tf.matmul(\n",
    "            valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "        \n",
    "        init = tf.initialize_all_variables()\n",
    "    \n",
    "    with tf.Session(graph=graph) as session:\n",
    "        \n",
    "        init.run()\n",
    "        print(\"Initialized\")\n",
    "        #saver = tf.train.Saver({'In'})\n",
    "        \n",
    "        average_loss = 0\n",
    "        for step in xrange(num_steps):\n",
    "            batch_inputs, batch_labels = gen_batch(\n",
    "                data, batch_size, skip_window, num_skips)\n",
    "            feed_dict = {train_inputs : batch_inputs, \n",
    "                         train_labels : batch_labels}\n",
    "            \n",
    "            _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "            average_loss += loss_val\n",
    "\n",
    "        \n",
    "            if step % 2000 == 0:\n",
    "                if step > 0:\n",
    "                    average_loss /= 2000\n",
    "                # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "                print(\"Average loss at step \", step, \": \", average_loss)\n",
    "                average_loss = 0\n",
    "\n",
    "            # Note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "            if step % 10000 == 0 and step > 0:\n",
    "                sim = similarity.eval()\n",
    "                for i in xrange(valid_size):\n",
    "                    valid_word = revdic[valid_examples[i]]\n",
    "                    top_k = 8 # number of nearest neighbors\n",
    "                    nearest = (-sim[i, :]).argsort()[1:top_k+1]\n",
    "                    log_str = \"Nearest to %s:\" % valid_word\n",
    "                    for k in xrange(top_k):\n",
    "                        close_word = revdic[nearest[k]]\n",
    "                        log_str = \"%s %s,\" % (log_str, close_word)\n",
    "                    print(log_str)\n",
    "\n",
    "        final_embeddings = normalized_embeddings.eval()\n",
    "        return final_embeddings\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev = 0\n",
    "\n",
    "words = load()\n",
    "KB = prep_graph(words)\n",
    "number_words = KB.number_of_nodes()\n",
    "batch_size = 256\n",
    "embedding_size = 100  # Dimension of the embedding vector.\n",
    "skip_window = 3      # How many words to consider left and right.\n",
    "num_skips = 4         # How many times to reuse an input to generate a label.\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors. Here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent.\n",
    "valid_size = 200    # Random set of words to evaluate similarity on.\n",
    "valid_window = number_words  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "num_sampled = 100    # Number of negative examples to sample.\n",
    "num_steps = 20000\n",
    "assert batch_size % num_skips == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step  0 :  327.263061523\n",
      "Average loss at step  2000 :  37.4282845838\n",
      "Average loss at step  4000 :  6.95995280075\n",
      "Average loss at step  6000 :  5.64904360628\n",
      "Average loss at step  8000 :  5.35014919043\n",
      "Average loss at step  10000 :  5.26306878948\n",
      "Nearest to folding: www, _food_, wherever, _You_, pages, moments, insolence, hoarse,\n",
      "Nearest to compass: confiding, defects, advise, Every, distress, V, ,, unaffected,\n",
      "Nearest to affirmative: mad, reproaches, if, vouch, deprive, re, nearly, told,\n",
      "Nearest to board: appearance, tolerably, invited, graces, pass, exact, thinks, teeth,\n",
      "Nearest to conveying: 24, Hearts, abrupt, hundred, DISTRIBUTOR, Dawson, )(, barely,\n",
      "Nearest to resisting: agree, intimacy, Suppose, Ugh, passed, rope, caprice, eight,\n",
      "Nearest to study: promised, lives, superciliousness, characters, comes, attending, till, exhibiting,\n",
      "Nearest to approached: exists, pointed, grin, warned, Caterpillar, draughts, facts, _more_,\n",
      "Nearest to Engaged: pianoforte, Boots, 58, trotting, testimony, modesty, readily, insolent,\n",
      "Nearest to briefly: per, coaxing, porridge, useful, carefully, by, Compliance, benefited,\n",
      "Nearest to road: kettle, hopeless, sounds, pan, manor, receive, accomplishment, week,\n",
      "Nearest to cease: timidly, cards, conceal, Caterpillar, shiver, giddiness, parental, deserved,\n",
      "Nearest to shorter: hypertext, matter, earliest, satisfactory, moreover, everywhere, Pepper, belief,\n",
      "Nearest to destined: settle, think, house, Long, NEGLIGENCE, And, care, teach,\n",
      "Nearest to _we_: copies, salad, listened, engaged, deprived, Conjectures, considering, Sometimes,\n",
      "Nearest to befriended: hesitated, cambric, witness, evil, growling, sleepy, abilities, applied,\n",
      "Nearest to Ambition: binary, alleviate, hints, nobody, impressing, chambermaid, instead, proprietary,\n",
      "Nearest to originate: in, drawn, surpass, hasty, ruining, stole, LIMITED, Chatsworth,\n",
      "Nearest to quite: woman, coach, press, suffering, mouths, Pennyworth, best, matrimonial,\n",
      "Nearest to misleading: sister, approach, Exceedingly, interference, imagined, depend, butter, proxy,\n",
      "Nearest to do: mean, I, They, wait, dwelt, mad, Bennets, lot,\n",
      "Nearest to pretending: syllable, contents, variety, comes, electronically, ignorant, then, imperfectly,\n",
      "Nearest to sufficiently: night, ,, illiterate, nursing, explain, never, paddock, Come,\n",
      "Nearest to inconsiderable: BROTHER, insulting, enabled, removed, speeches, distressing, abilities, render,\n",
      "Nearest to affability: Five, mad, striking, omen, Chamberlayne, Ahem, henceforth, Ada,\n",
      "Nearest to tomorrow: knows, comparative, undo, motives, sincere, mantelpiece, anguish, indebted,\n",
      "Nearest to prevent: supposition, Robinson, practice, Militia, apologise, conscious, send, such,\n",
      "Nearest to shilling: written, synonymous, awake, breathe, exerting, render, inspection, complaints,\n",
      "Nearest to privately: the, serpent, Caterpillar, wooden, mad, ride, remark, incensed,\n",
      "Nearest to caught: moving, left, pleased, pencil, provide, Charlotte, lover, supposing,\n",
      "Nearest to contrive: music, excited, --, copyright, Society, PREJUDICE, *, wearily,\n",
      "Nearest to superseded: girls, Darcy, authorised, pressing, company, resolved, snug, PROVIDED,\n",
      "Nearest to recommendations: Arithmetic, felicity, 35, hundreds, with, Charles, delight, natured,\n",
      "Nearest to sea: mortifications, inclined, alternate, mistaken, immediate, tempt, damages, finger,\n",
      "Nearest to Smiles: scrambling, borne, feelings, Brother, own, fees, provision, confidential,\n",
      "Nearest to hollow: fainter, playing, reading, unimportant, pleasing, Kent, aspire, smiling,\n",
      "Nearest to quiver: wasting, person, universally, openly, dullness, help, paw, unjustifiable,\n",
      "Nearest to Stay: untinctured, termed, kingdom, account, deeply, business, thump, volume,\n",
      "Nearest to intervals: some, duties, accepting, husbands, imitate, dipped, interrupted, petition,\n",
      "Nearest to Queens: _month_, northward, tide, assertions, prey, arising, heard, candle,\n",
      "Nearest to thoughts: Jane, Caterpillar, character, Well, On, Footman, mixture, unwillingly,\n",
      "Nearest to ample: ,, imagine, more, casual, ready, forwards, credit, _begin_,\n",
      "Nearest to awful: rose, scandalous, These, recurring, anguish, particularly, foot, missed,\n",
      "Nearest to Under: recollections, possessed, herself, neglecting, Go, staircase, liveliest, rector,\n",
      "Nearest to disrespectful: stamp, charming, indifferent, melancholy, applicable, intruder, Mrs, walrus,\n",
      "Nearest to singers: adventures, proprietor, undoubtedly, spell, GAVE, Was, unimportant, move,\n",
      "Nearest to deference: green, ,, kindness, blacken, augmented, 33, dressing, FOUNDATION,\n",
      "Nearest to spiritless: directly, chain, harm, quickly, lowing, brother, lesson, Pat,\n",
      "Nearest to conscience: essentials, cough, bewildered, elbow, beasts, acknowledgments, to, thoughts,\n",
      "Nearest to flow: gaming, disheartened, fright, teacup, revolving, repeating, seize, verses,\n",
      "Nearest to signs: Vanity, faithfully, overthrowing, :”, BUT, dine, _are_, succeeding,\n",
      "Nearest to bough: cheap, vouch, _laugh_, ecstasy, refusing, cats, beneath, correct,\n",
      "Nearest to purse: lines, Church, unfolded, volunteer, importance, trotting, censured, impudent,\n",
      "Nearest to conceit: affected, meat, writes, development, mantelpiece, write, posted, estimation,\n",
      "Nearest to uttered: ashamed, rise, expense, symmetry, perceptible, youngest, singular, Heads,\n",
      "Nearest to provisions: ornamented, fond, succeeds, ferrets, room, watch, vestibule, naturally,\n",
      "Nearest to servants: which, view, checking, indirect, twelfth, saw, warded, engagements,\n",
      "Nearest to 6: deep, precluding, Pennyworth, Yet, inn, such, morrow, unimportant,\n",
      "Nearest to previous: rallied, engrossed, Everybody, mad, rein, began, suppose, cats,\n",
      "Nearest to digressions: distributing, reason, enter, follows, purchase, best, Conqueror, 60,\n",
      "Nearest to absolute: madam, All, impudent, travellers, decisive, push, ., Stop,\n",
      "Nearest to Merely: inviting, grieve, punishment, venture, choice, yours, shop, obstinate,\n",
      "Nearest to wider: belief, contrivance, rate, _such_, travellers, proceed, howling, warmth,\n",
      "Nearest to Newby: Pray, unimportant, inquiring, atone, showed, condescended, tallest, Bath,\n",
      "Nearest to made: liberal, state, labour, prevented, QUEEN, September, days, unwelcome,\n",
      "Nearest to barking: cordial, regulate, backwards, comfort, She, howled, substantial, doleful,\n",
      "Nearest to fearing: resolving, void, whistle, danger, Caterpillar, direction, pleasing, twist,\n",
      "Nearest to neglecting: codes, Jenkinson, remarking, nurse, Certainly, Anne, off, virus,\n",
      "Nearest to grasp: ham, judged, debts, park, such, quantity, die, unheard,\n",
      "Nearest to soft: lad, employed, ever, say, receipt, combated, Caterpillar, release,\n",
      "Nearest to ravens: backgammon, coaxing, decorum, Even, entreaties, carried, kid, wood,\n",
      "Nearest to de: verse, kindness, withdrawing, Accordingly, enjoyment, fact, _is_, confirms,\n",
      "Nearest to never: daughters, dipped, have, continuance, bend, except, ,, come,\n",
      "Nearest to Yet: resolve, complaints, forgive, 6, Take, :”, agreed, incapable,\n",
      "Nearest to pleasing: Caroline, upon, ornament, unimportant, messages, evenness, establishment, attributed,\n",
      "Nearest to quarters: twinkling, tend, Besides, OUT, spent, solemnly, Most, termination,\n",
      "Nearest to intermarriage: gravity, race, remarkable, lying, impudence, mouths, Run, Persuaded,\n",
      "Nearest to Hand: affront, An, fortunate, kept, awake, mad, ought, strike,\n",
      "Nearest to fetched: tall, sneering, mistakes, tenderness, esteem, breakfast, hearts, punctually,\n",
      "Nearest to spoon: impatiently, loss, _advantages_, hole, speedily, succeeded, entreated, formerly,\n",
      "Nearest to palatable: House, doing, lieu, entreaty, interference, acute, danced, admit,\n",
      "Nearest to overheard: FENDER, proved, late, honoured, mad, lived, stairs, glad,\n",
      "Nearest to instrument: tried, misused, incomprehensible, learnt, ”, malicious, paragraph, to,\n",
      "Nearest to remove: evenings, cucumber, ;--, grinned, excellent, Denny, watching, solicit,\n",
      "Nearest to trampled: indignation, indemnify, unavoidable, paused, kitchen, connected, decisive, ugly,\n",
      "Nearest to disservice: muscular, mother, ;, taxes, condescension, example, silliest, inducements,\n",
      "Nearest to totally: winking, computer, rail, waste, command, punishment, doubts, overcame,\n",
      "Nearest to ardent: patience, Suppose, cheeks, slight, B, bewitched, note, ,,\n",
      "Nearest to proclaim: tone, WAS, YOU, new, Lory, listening, tempted, declined,\n",
      "Nearest to arrow: disclosed, to, rank, I, grove, Caterpillar, shoes, boasted,\n",
      "Nearest to variations: kissed, arrange, Heaven, five, expressing, comply, corners, heart,\n",
      "Nearest to some: intervals, the, creditors, mad, accepting, Fainting, advanced, man,\n",
      "Nearest to shop: unimportant, Pemberley, them, familiarity, thoroughly, _another, voices, remedy,\n",
      "Nearest to lives: FOUNDATION, profligacy, removal, trotting, camp, trial, dinn, interruptions,\n",
      "Nearest to whichever: surmise, recommendation, interpreted, current, ride, meet, dilatory, teach,\n",
      "Nearest to offered: ringlets, universities, refreshments, late, hazarded, unless, departure, sour,\n",
      "Nearest to March: Long, Caterpillar, Bill, Robinson, ;--, care, haste, humble,\n",
      "Nearest to one: indignation, Soup, subsisting, culprit, service, attend, requirements, doors,\n",
      "Nearest to neither: sermon, journey, utmost, ball, expressive, describe, assistant, Rabbit,\n",
      "Nearest to profligacy: lives, should, trotting, uncorked, intolerable, things, Robinson, indulged,\n",
      "Nearest to meditated: tell, THERE, downstairs, thoughts, amazing, 13, mechanically, faults,\n",
      "Nearest to Fourteenth: trace, livings, abusing, latter, Each, countenance, rat, absolutely,\n",
      "Nearest to _conditionally_: gazing, rather, subsequent, there, sudden, poorly, sits, arrum,\n",
      "Nearest to thunder: new, Christmas, wonders, expectation, unhappy, lurking, apply, communicativeness,\n",
      "Nearest to Undoubtedly: pinched, intended, readily, Hearts, specific, effect, seasonable, containing,\n",
      "Nearest to inferiority: sole, expecting, stranger, Caterpillar, Aye, old, discourses, cast,\n",
      "Nearest to unprepared: comfort, eBook, repulsed, Found, concerning, tenants, suppose, begged,\n",
      "Nearest to bounty: feathers, gallons, piece, impatiently, loud, infancy, Project, In,\n",
      "Nearest to upbraiding: North, _should_, William, feeling, dictates, explained, _his_, YOUR,\n",
      "Nearest to start: transport, earliest, suit, adventures, ringlets, reminding, crying, defects,\n",
      "Nearest to prettyish: raising, Chapter, cousins, path, ashamed, candle, apology, come,\n",
      "Nearest to pardon: pleasantry, difficulty, cordially, folly, afflicting, clothes, cultivation, begins,\n",
      "Nearest to IS: accepted, furnish, back, join, juror, chance, constitution, fishing,\n",
      "Nearest to person_: expostulation, pity, Sing, crawled, Sometimes, intimacy, wavering, preceding,\n",
      "Nearest to wisely: fight, market, susceptibility, York, fees, oop, sagacity, coincide,\n",
      "Nearest to exactly: hand, army, wished, _feel_, disappointing, dawdled, comforted, remind,\n",
      "Nearest to Shall: sunk, bracelets, _I_, throwing, improved, the, advise, shrink,\n",
      "Nearest to resentfully: England, disappointment, Forster, laugh, humbly, bandbox, _know_, leaves,\n",
      "Nearest to short: complaints, inhumanity, charms, accepting, chooses, separated, suppose, change,\n",
      "Nearest to liberty: ‘“, pecuniary, upon, Run, phaeton, ringlets, rude, yards,\n",
      "Nearest to stretched: anywhere, difference, retail, welcomed, future, a, crowd, exceeding,\n",
      "Nearest to _coming: cry, cunning, Email, suffer, lobsters, unabashed, strangeness, universally,\n",
      "Nearest to IF: accordingly, deserts, unusually, lies, more, other, apples, trot,\n",
      "Nearest to obstacle: gratification, increased, because, play, abilities, PREJUDICE, do, sort,\n",
      "Nearest to guided: _such_, ):--, conceal, Don, Remember, Where, excess, replace,\n",
      "Nearest to .--‘: violated, rats, Hunsford, muchness, insufferable, questions, park, flirtation,\n",
      "Nearest to treading: expressed, conjecturing, bark, contrived, mortification, sought, hesitating, avoidance,\n",
      "Nearest to mutually: lady, surprised, _You_, entered, hat, self, dare, looks,\n",
      "Nearest to pretend: using, inclinations, greater, paid, ,, public, Westerham, undone,\n",
      "Nearest to restoration: obliged, parish, lost, abominable, knee, minute, frightened, prospect,\n",
      "Nearest to disobliging: bells, THERE, argued, pouring, Hare, custom, defiance, invitation,\n",
      "Nearest to headache: strongly, shameful, correspondent, degrees, official, fork, ANY, Much,\n",
      "Nearest to accents: absence, unrolled, care, hasten, taken, encouraging, birth, unusual,\n",
      "Nearest to conversing: intelligent, ready, Nonsense, kindly, jokes, throat, limbs, suffered,\n",
      "Nearest to view: servants, tale, innocent, 12, disappointment, suitable, pocket, attention,\n",
      "Nearest to mention: Wickham, liberally, Web, Mock, stick, But, rate, WHAT,\n",
      "Nearest to _now_: mad, begged, stick, duck, Sir, trifle, B, Probably,\n",
      "Nearest to compose: shedding, content, breakfast, Never, 5, body, croquet, minute,\n",
      "Nearest to Observing: shire, yesterday, third, messages, being, GAVE, Street, contrast,\n",
      "Nearest to spoilt: Longbourn, pleasure, without, Caterpillar, diffident, readable, observances, Meryton,\n",
      "Nearest to prettier: tide, bowed, wishing, understood, simply, shore, everyone, their,\n",
      "Nearest to success: went, Their, defective, proficient, involve, lift, continued, transcribe,\n",
      "Nearest to We: adventures, shower, unimportant, enjoying, veneration, ladyship, jug, doesn,\n",
      "Nearest to Blame: surveying, best, neighbour, cows, wantonly, mediocrity, Widely, Eastbourne,\n",
      "Nearest to oldest: Twice, refreshing, sir, dry, gratification, rites, Sends, arise,\n",
      "Nearest to furrows: Paris, Tale, bit, bracelets, costs, nowadays, indirect, certainly,\n",
      "Nearest to Is: Volunteers, X, mad, unshaken, agreeable, Ashworth, Forsters, implacability,\n",
      "Nearest to tastes: stranger, look, amusements, allurements, space, doubtingly, satirical, Drawling,\n",
      "Nearest to ,”--: two, captivating, Probably, !”, sentence, rises, Reynolds, horses,\n",
      "Nearest to signed: fork, recovery, warn, lobby, ANY, letter, .”, paler,\n",
      "Nearest to insinuating: as, confidence, her, military, Widely, have, indirect, rabbit,\n",
      "Nearest to operated: spreading, comprehension, Both, Why, congratulate, emphatically, use, temptations,\n",
      "Nearest to electronically: then, bare, Digging, miss, fortunate, mud, youth, next,\n",
      "Nearest to surely: Half, greatest, 2, uncivil, distribute, cats, perceiving, uncertainty,\n",
      "Nearest to surprise: Robinson, People, gravely, sermon, sincere, oblige, gratefully, offer,\n",
      "Nearest to buttons: Westerham, medium, coach, Eaglet, paw, equal, verily, moments,\n",
      "Nearest to hedges: Jane, yield, guard, fly, aroused, chorus, emphatically, ootiful,\n",
      "Nearest to fear: computer, 52, calling, repeat, estimated, cannot, Talking, qualities,\n",
      "Nearest to Dining: lobby, nicely, eager, uncomfortable, Use, falsely, LICENSE, AK,\n",
      "Nearest to hackneyed: expense, route, net, humble, pounds, cared, ride, took,\n",
      "Nearest to displayed: occupies, distinguished, officious, compromised, violence, politeness, cards, worm,\n",
      "Nearest to park: half, haste, feet, Conjectures, party, dwelt, snorting, mad,\n",
      "Nearest to turkey: extended, extracts, repose, persuade, heads, performers, daughters, _violent,\n",
      "Nearest to steady: slacken, affront, always, small, subsisting, mad, intentionally, departure,\n",
      "Nearest to haven: suspected, ., FOR, the, view, tortured, toilette, PLEASE,\n",
      "Nearest to Oh: King, melancholy, pieces, authoritative, gratified, insist, accompanying, boast,\n",
      "Nearest to unalloyed: muscular, represent, constantly, adoration, advantages, easy, gayer, treat,\n",
      "Nearest to tone: proclaim, comprehended, exquisite, headstrong, 11, Having, Lucases, irrevocably,\n",
      "Nearest to defect: sphere, sometimes, elevating, mad, Pulvis, clearing, readily, disposition,\n",
      "Nearest to door: supper, canvas, compassion, forgave, Caterpillar, registered, C, deemed,\n",
      "Nearest to awed: scorn, listen, lazy, Multiplication, chance, license, correspond, preserve,\n",
      "Nearest to _Her_: late, awfully, reflection, sacrifice, Miss, sensibility, she, milk,\n",
      "Nearest to puzzle: twenty, spend, barrowful, tiresome, fully, ?, follow, During,\n",
      "Nearest to distributed: represent, irregularity, incredible, laughed, these, greater, scream, bridge,\n",
      "Nearest to balanced: lost, false, _they_, hatters, proposed, prohibition, parish, reproach,\n",
      "Nearest to brains: Sounds, !”?’, Darcy_, surrounding, Respect, kinds, abusing, underneath,\n",
      "Nearest to printed: led, 1342, _he_, assented, amongst, advise, vows, attributed,\n",
      "Nearest to exercising: takes, mirth, sun, formality, Blenheim, attachment, So, changes,\n",
      "Nearest to stoop: cared, collection, tis, less, discernible, Paris, accuracy, showing,\n",
      "Nearest to discontinuance: desiring, followed, undoubtedly, chop, swimming, step, learned, allusion,\n",
      "Nearest to partake: Speak, find, 7, fresh, youngest, as, gravy, soul,\n",
      "Nearest to seven: correspond, has, domestics, suspected, _two_, feared, endured, copied,\n",
      "Nearest to ADVENTURES: pink, knife, agitations, Director, comforts, bent, indelicate, goals,\n",
      "Nearest to bosom: low, judgment, sending, regiment, Depend, Writhing, elopement, leaves,\n",
      "Nearest to ourselves: Single, sharply, Persuaded, melancholy, sh, respectable, union, about,\n",
      "Nearest to induced: undo, pope, draw, pleased, performances, keenest, woods, censure,\n",
      "Nearest to affinity: grew, planned, pay, guest, Pleased, Charles, so, dream,\n",
      "Nearest to bride: service, ensigncy, hadn, sharply, however, SHE, dread, intention,\n",
      "Nearest to Though: Those, NEVER, refuse, latter, practically, regarding, What, betrayed,\n",
      "Nearest to course: friends, wishes, death, opportunities, em, preparing, lucky, during,\n",
      "Nearest to enjoyment: called, stood, occasions, dislike, sharers, tolerable, tradesman, dull,\n",
      "Nearest to recollect: avoidance, *****, undeserved, _Too, concerto, ornament, fits, afflicted,\n",
      "Nearest to burning: lurking, mischievously, follies, idiotic, parental, Whenever, reached, match,\n",
      "Nearest to Persuaded: ourselves, orderly, _me_, Woods, thin, lively, hole, duets,\n",
      "Nearest to clamorous: discovery, expected, represented, imparted, ME, expedite, practising, request,\n",
      "Nearest to obstinate: solicitude, tails, scruple, anguish, mad, objection, grieve, necessity,\n",
      "Nearest to hope: Drawling, rabbit, agreement, Make, gratify, tempered, treasure, militia,\n",
      "Nearest to disregarded: watch, directions, unnaturally, Into, Right, utmost, reflections, License,\n",
      "Nearest to echo: sure, suit, _me_, asleep, across, drink, stout, collection,\n",
      "Nearest to unlink: congratulatory, gentle, imposed, ordination, flamingo, crab, tempt, Monday,\n",
      "Average loss at step  12000 :  5.23262168777\n",
      "Average loss at step  14000 :  5.24752419829\n",
      "Average loss at step  16000 :  5.20109228277\n",
      "Average loss at step  18000 :  5.16508597696\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "vocab_size = KB.number_of_nodes()\n",
    "revdic = {node[1]['number']: node[0] for node in KB.nodes(True)}\n",
    "\n",
    "words_n = words[prev: prev+10000]\n",
    "data = [KB.node[word]['number'] for word in words_n]\n",
    "\n",
    "data, dic, revdic = build_vocab(words, vocab_size)\n",
    "embeddings = W2V(batch_size, embedding_size, skip_window,\n",
    "            num_skips, valid_size, valid_window,\n",
    "            valid_examples, num_sampled, vocab_size,\n",
    "            num_steps, data, revdic)\n",
    "\n",
    "prev += 10000\n",
    "#words_n, KB = add_level(words[prev: prev+10000], embeddings, KB, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1267: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  distances = np.zeros(self.batch_size, dtype=np.float64)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1279: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, init_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1279: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  0, n_samples - 1, init_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:630: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, init_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:630: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  0, n_samples - 1, init_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:630: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, init_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:630: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, init_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1328: DeprecationWarning: This function is deprecated. Please call randint(0, 74358 + 1) instead\n",
      "  0, n_samples - 1, self.batch_size)\n",
      "/home/lenny/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py:1384: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.cluster_centers_) for s in slices]\n"
     ]
    }
   ],
   "source": [
    "words_n = words[100000:150000]\n",
    "words_n, KB = add_level(words_n, embeddings, KB, 1000)\n",
    "vocab_size = KB.number_of_nodes()\n",
    "revdic = {node[1]['number']: node[0] for node in KB.nodes(True)}\n",
    "data = [KB.node[word]['number'] for word in words_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step  0 :  387.60723877\n",
      "Average loss at step  2000 :  69.9865728245\n",
      "Average loss at step  4000 :  9.01119960183\n",
      "Average loss at step  6000 :  3.6344371556\n",
      "Average loss at step  8000 :  2.63510841748\n",
      "Average loss at step  10000 :  2.29744554491\n",
      "Nearest to among: beauty, 18863, 19699, 19781, 19408, 19461, evil, pay,\n",
      "Nearest to facts: breast, 19323, 16217, 19179, appeared, 18915, 10342, 19072,\n",
      "Nearest to ladder: 11590, bedrooms, obliging, extras, 15786, 19490, bowed, 16736,\n",
      "Nearest to upper: 18882, 19383, 8991, 9769, own, colouring, 9642, 9119,\n",
      "Nearest to concealment: 16416, 15912, 18557, 9305, 17676, 13565, $, commended,\n",
      "Nearest to pet: policy, cool, talked, 18731, 15075, 15025, stronger, 17875,\n",
      "Nearest to coquetry: if, 11978, am, 9118, mistakes, individual, 12574, 19855,\n",
      "Nearest to certainty: civilities, 18296, care, 12077, 8828, 17858, 11783, Though,\n",
      "Nearest to connivance: 15070, 18240, 15875, 14404, 8668, 15272, enjoying, 14316,\n",
      "Nearest to soothing: 14516, 16209, 17924, 17089, 14629, 11633, 19346, glanced,\n",
      "Nearest to Blame: 19013, 11345, 13460, casual, dancing, 20055, wonder, 13334,\n",
      "Nearest to fruit: 9352, 13574, amusement, unwilling, dress, 19401, 9107, 10128,\n",
      "Nearest to Sentence: cautioning, 8689, 10700, guardian, 10254, 9339, 16019, 12540,\n",
      "Nearest to strange: yesterday, 9218, preference, 16559, 19894, explain, parsonage, 9948,\n",
      "Nearest to rapid: silence, 18981, 19548, 11894, 12526, 19157, stuffy, coming,\n",
      "Nearest to nuptials: 18450, breach, 17694, 9690, 14450, 17435, 10191, 13976,\n",
      "Nearest to equal: 19921, 11713, 19585, Nay, 18454, 10198, 9012, 17152,\n",
      "Nearest to forgiveness: schemes, 11604, archly, 15108, 8912, _He_, benevolence, 18135,\n",
      "Nearest to assembled: 11781, 19265, lastly, 16217, constitution, 19041, _You_, 18990,\n",
      "Nearest to assertion: 16807, 11120, 19462, quick, describing, With, mean, persuaded,\n",
      "Nearest to induce: 16758, endeavours, 16779, 9705, affectionately, 10234, 15446, 17559,\n",
      "Nearest to smoke: unlocking, Stigand, 13528, 8960, 8678, 14212, unnecessary, 13331,\n",
      "Nearest to concise: 15647, 13049, fearing, 16464, fire, become, 17665, --,\n",
      "Nearest to weakness: 17745, 18228, earliest, 18126, intentionally, removal, 12039, 19700,\n",
      "Nearest to theirs: busy, 14778, 18064, redistribute, 17254, 14943, protest, 9203,\n",
      "Nearest to censuring: 12418, 13881, 18982, ample, 17140, 11336, 10539, embargo,\n",
      "Nearest to stranger: satisfy, 12292, fell, composure, 11921, 19740, 19888, _not_,\n",
      "Nearest to quit: binary, 10067, 9026, heirs, glory, REMEDIES, 9055, stalk,\n",
      "Nearest to denial: 19002, grandeur, history, 19082, chicken, 19586, distant, obliged,\n",
      "Nearest to detaining: 19068, dismission, spoken, thanking, rude, vestibule, 19371, deserve,\n",
      "Nearest to Keep: 12767, 14608, fulfil, 19948, 16571, Hadn, Maybe, judged,\n",
      "Nearest to page: 13140, 9788, 11634, 15149, Scarborough, 11609, 18202, day,\n",
      "Nearest to Anxious: stroll, retreated, disturbers, dependent, 11935, 10273, 12939, 18576,\n",
      "Nearest to attics: managing, 11847, 18447, 17340, 14402, 17250, 16345, horror,\n",
      "Nearest to SHOES: 12356, 14694, 11512, 15982, 16352, 11489, 14555, 13641,\n",
      "Nearest to disgracing: dared, 12309, 12871, 20059, sensible, 19114, 16126, offers,\n",
      "Nearest to assumed: 13018, remarkable, met, 19884, supposing, 17521, getting, Against,\n",
      "Nearest to fast: 12067, pronouncing, Despite, 16759, 14895, separately, 10366, 18172,\n",
      "Nearest to Three: variations, 17653, usual, Service, 15231, _Mr, 10334, abominable,\n",
      "Nearest to shouldn: 9217, Mock, try, 19177, 19596, 12023, abominate, driven,\n",
      "Nearest to sink: bewailed, principal, 18794, 11936, Pray, 18521, 18409, imperturbably,\n",
      "Nearest to protect: prove, 16495, despaired, 14692, 17369, 17727, 10157, 11229,\n",
      "Nearest to signed: 9485, 12504, 14178, 12676, 16632, 18180, 8994, 9502,\n",
      "Nearest to continued: 13020, society, 10151, 10618, trusting, 19616, 12777, occurrences,\n",
      "Nearest to shrill: visits, 13881, 14826, 9078, 9516, packed, 10370, revolt,\n",
      "Nearest to sanctioned: 18814, 11972, 19764, folly, 13858, 18114, interrupting, quite,\n",
      "Nearest to defects: 18626, 10862, please, unnecessary, 10117, 19771, Oh, nobody,\n",
      "Nearest to personages: unassailed, 17716, 16415, Wake, unbecoming, 17042, prize, 10005,\n",
      "Nearest to inherit: 18251, gave, 19621, 10038, 19917, 18810, 18379, exhibiting,\n",
      "Nearest to dry: morals, prosperous, 10468, 13904, miss, sanction, 16049, reality,\n",
      "Nearest to Nobody: 19926, 10218, 10641, 12773, couple, right, 11510, 11713,\n",
      "Nearest to ‘“: Hjckrrh, 17960, 18214, 16873, thimble, NOT, meetings, 13637,\n",
      "Nearest to refrained: 10523, grave, retort, 18415, unwelcome, 9896, alike, influence,\n",
      "Nearest to that: thus, undutiful, 12640, 9748, 10422, 11451, 16367, 16155,\n",
      "Nearest to universities: library, affront, 19207, elegance, restraint, 10881, considerable, rector,\n",
      "Nearest to start: despise, raised, broke, 15614, 14459, 15201, 13047, KIND,\n",
      "Nearest to suffers: 15808, objections, alas, 12876, 13410, 17015, 11171, 15096,\n",
      "Nearest to adept: 14359, undetermined, enhance, 18254, protesting, 13422, Hill, 19120,\n",
      "Nearest to Luckily: 15877, earl, exaggerate, newsletter, temporary, 15669, 19098, 8882,\n",
      "Nearest to expressions: 19917, 16837, 16682, 13067, 9928, cost, 19566, 19684,\n",
      "Nearest to unavailing: brilliancy, comprised, creature, admire, adding, civility, project, display,\n",
      "Nearest to globe: reached, 19538, 12388, Jack, 15416, 19225, 10417, 10644,\n",
      "Nearest to risk: unnecessary, 19352, rector, hours, kitchen, 9800, 12546, longer,\n",
      "Nearest to grace: 19179, 9859, 19432, kindly, appearing, amaze, 20007, advantages,\n",
      "Nearest to receipt: .’--, educations, 9820, 12264, 11321, Sarah, 8593, fare,\n",
      "Nearest to derived: 17648, 18236, 13842, Any, 14951, 9100, 11074, 15480,\n",
      "Nearest to overpowered: 19632, 13665, lady, 11799, affront, vary, 19415, amazes,\n",
      "Nearest to readiness: sure, Merely, 13777, talk, 19271, 13289, 11731, 19371,\n",
      "Nearest to Happiness: goodness, 14747, 13843, eyes_, 17437, 9498, 16836, 17660,\n",
      "Nearest to sufficient: 19627, 20050, 16597, 13052, resentment, 19251, not, 11550,\n",
      "Nearest to :--“: 9880, 19176, likely, frightened, still, information, 10629, 17139,\n",
      "Nearest to wisest: relationship, 10132, boast, 18339, 19046, 13819, 10195, creditably,\n",
      "Nearest to Edwin: 19582, 18097, 18592, lustre, 15705, 9350, 15708, tired,\n",
      "Nearest to Sit: 14697, 17869, Race, hardest, 13153, 17438, caprice, shrink,\n",
      "Nearest to toast: 8887, 10491, roof, final, volunteers, 12706, 14701, resting,\n",
      "Nearest to falsely: 14715, woody, /, 14470, Don, 14733, unabashed, 15155,\n",
      "Nearest to cartwheels: resolution, err, 10882, 10047, 19697, staggered, 18075, 18193,\n",
      "Nearest to letting: 13319, Carter, nowhere, 12521, 13681, yawned, Never, objections,\n",
      "Nearest to apothecary: supposition, 14005, Your, 17351, 19150, 14351, 15620, encouraging,\n",
      "Nearest to crab: 9388, 16383, 17514, 18480, inflicted, 10613, flamingoes, 10674,\n",
      "Nearest to affairs: 15817, 10825, 18308, regretting, 16269, recollecting, 15586, climb,\n",
      "Nearest to trumpet: punctuality, detaching, 15892, giddiness, 13889, pglaf, gbnewby, domain,\n",
      "Nearest to mien: branch, 10590, 13254, Soup, Adieu, inspired, 15565, 19050,\n",
      "Nearest to forbearance: 11309, 12331, atonement, crowd, wealth, 8955, 16807, amazed,\n",
      "Nearest to carried: 19823, etiquette, 19482, fault, beyond, 12346, 11955, 10515,\n",
      "Nearest to fan: 15543, READ, Respect, neatness, pursuits, 10797, 16737, 11708,\n",
      "Nearest to ere: 10351, whose, justified, 11138, 16703, felicity, 10430, 9229,\n",
      "Nearest to alienated: ’, 16658, 10433, 11004, 10200, 19518, _My_, 18223,\n",
      "Nearest to past: alarms, 16366, 14719, 14764, 9251, 15861, 17369, augmented,\n",
      "Nearest to indistinctly: kid, schoolroom, dull, 13712, 13359, dispirited, peeping, 16409,\n",
      "Nearest to conciliatory: 18957, Your, 19024, attending, 12643, 9212, 19892, 19657,\n",
      "Nearest to borrowed: 14492, Just, 15455, 13460, 8774, 11688, colds, Madam,\n",
      "Nearest to downs: 14218, comprise, 10772, 17413, panegyric, upsetting, dialogue, bats,\n",
      "Nearest to can: lest, efforts, have, determination, nothings, 17091, related, 19903,\n",
      "Nearest to foxhounds: 11827, stone, unworthy, 15495, 10221, things, aware, 14370,\n",
      "Nearest to employed: intentionally, 11984, 11805, 19663, 11927, gone, neighbours, totally,\n",
      "Nearest to weighed: leant, 15733, 11539, 10179, profusion, Hart, 9774, 17277,\n",
      "Nearest to horse: inspiring, 16712, windows, approved, 8658, 19730, 11603, detection,\n",
      "Nearest to taken: voice, importance, 17906, refusal, 16743, 18713, Mary, 9723,\n",
      "Nearest to suggestion: 19412, group, judging, 13996, 19214, destitute, relieve, 10703,\n",
      "Nearest to yelp: defined, rock, MILE, 9385, 16329, 18664, Kympton, 18236,\n",
      "Nearest to overbearing: reason, croqueted, 16670, 12084, 17772, 19550, 15019, PRIDE,\n",
      "Nearest to walks: 9563, 17548, 17163, maternal, 17904, industriously, 9501, 13209,\n",
      "Nearest to manifold: used, suddenness, 19234, eating, 18882, 19538, 19084, 19073,\n",
      "Nearest to despair: enemies, seeing, thinks, 19535, 17422, 19751, avail, delighted,\n",
      "Nearest to Five: 10532, 9181, 18257, Ahem, 16686, 18366, fashionable, grateful,\n",
      "Nearest to comforted: adieus, 16549, levelled, 17525, 14557, 10715, 15496, 15847,\n",
      "Nearest to expectation: gloomy, 17267, 9833, 10032, _retaining_, 11840, grand, 12452,\n",
      "Nearest to FIT: Improve, postponed, survey, 12462, baby, improved, drew, pie,\n",
      "Nearest to Revenue: _right_, emptiness, chin, 13753, serpents, lieu, agreed, Collar,\n",
      "Nearest to lefthand: faint, sentence, checking, 9371, friendless, 14196, 9120, 13737,\n",
      "Nearest to Fatigued: 15363, prized, 16559, 19617, accidental, 9432, 11421, 16919,\n",
      "Nearest to rapped: 12163, 18983, 10345, 16076, prompt, 19618, sunk, 15544,\n",
      "Nearest to SLUGGARD: 14390, 18367, Reflection, 13451, few, offend, 11178, 12778,\n",
      "Nearest to plead: amiable, 9414, 10459, triumph, am, murmurs, satisfied, 17473,\n",
      "Nearest to port: most, 19821, 9107, 18510, 19662, coats, 18441, 12928,\n",
      "Nearest to formation: piece, 15491, earlier, 15455, learned, 12832, impunity, LICENSE,\n",
      "Nearest to servility: 14800, 10826, 12530, revealing, 12943, bordered, 8783, indulge,\n",
      "Nearest to forbore: 11929, Britain, 15981, pliancy, loveliest, 15105, 12090, grass,\n",
      "Nearest to wearisome: 13347, 9573, 13360, 14570, 12186, 13392, 13284, neighbour,\n",
      "Nearest to uselessly: 16000, 15340, 15406, 14625, precious, shoot, 18842, 15585,\n",
      "Nearest to deserve: 11894, careful, 12112, 13221, detaining, intimacy, 16666, 18454,\n",
      "Nearest to starve: 18519, patroness, Nile, 11238, 18781, 11139, crowned, whichever,\n",
      "Nearest to way: 10937, continual, letter, 9292, 11647, 19680, 17284, urged,\n",
      "Nearest to remonstrance: 11090, m, 10451, twice, 9106, Watson, 14648, 11241,\n",
      "Nearest to weight: idiotic, gate, 14902, 10541, 17704, _to_, tour, 16446,\n",
      "Nearest to indignity: 15037, 14904, 9814, fishing, 18998, 17438, 18701, nice,\n",
      "Nearest to nine: recollections, Under, created, 16386, 12875, 14797, howling, group,\n",
      "Nearest to doubly: 13857, Except, sounds, 13637, errors, pair, intimation, repaired,\n",
      "Nearest to elope: 18801, hatter, inconvenience, 12533, 15096, 16280, gay, 14379,\n",
      "Nearest to thankfully: 11357, 10447, 17797, 14362, disposal, 17349, 18103, 15588,\n",
      "Nearest to testified: 9051, 13252, backwards, nectarines, 12301, 15331, 13319, heartedness,\n",
      "Nearest to Engaged: 17583, Chapter, nothings, however, joining, hurt, consulting, 18454,\n",
      "Nearest to domestic: scolded, poor, through, Her, answered, 18083, 19208, 11703,\n",
      "Nearest to indecorum: mix, 14916, jestingly, 15099, 13997, 16180, 12490, fat,\n",
      "Nearest to either: 17877, 19504, 10110, 9364, 18945, 19586, disappointment, discomposed,\n",
      "Nearest to fall: 17217, walrus, 13215, 12591, whispered, 9415, sharks, 13110,\n",
      "Nearest to dined: overcoming, 16684, 11396, ?”’, 16505, performing, viewed, 14848,\n",
      "Nearest to great: 9179, 12069, 9660, 9370, unkindness, afraid, perceived, 10422,\n",
      "Nearest to MINE: cruelty, melancholy, unpardonable, 9270, thump, 19249, fluently, betray,\n",
      "Nearest to sneezes: breath, 18140, 11616, 13231, Silence, 9536, 16148, 13249,\n",
      "Nearest to endeared: 11374, 15356, Yes, Women, 18974, resisting, intrusion, 9074,\n",
      "Nearest to unexpectedly: regret, 10915, steady, trusted, addressed, send, insensibility, 19903,\n",
      "Nearest to proportion: 8675, 8722, need, USE, 14513, inwards, 15312, nicely,\n",
      "Nearest to alluded: irritation, 18005, prompted, tendency, 19269, 19606, 18243, Elizabeth,\n",
      "Nearest to humbly: publish, sometimes, 18256, 9692, 13982, hearing, smoking, 10237,\n",
      "Nearest to quarter: regarding, back, ladyship, aloud, 17382, integrity, preparing, who,\n",
      "Nearest to pray: 18810, 11232, 19850, different, truest, instrument, 19995, 9407,\n",
      "Nearest to despaired: 16792, 17182, Digging, protect, unbending, indulgence, 13629, 17232,\n",
      "Nearest to riper: 10267, lover, regrets, 9518, art, 17591, 14157, 19063,\n",
      "Nearest to perforce: 12526, 18978, 13950, absurd, 12408, 9703, If, sir,\n",
      "Nearest to eccentric: interruption, 11836, Seven, wants, go, On, licentiousness, 9982,\n",
      "Nearest to deficiency: 19865, bestowed, 11066, 9581, informality, Meryton, 16984, 17505,\n",
      "Nearest to _ought_: 19823, 13302, often, 19620, adjusting, across, 19283, 10138,\n",
      "Nearest to YOURS: 17432, 16066, 13818, 13262, 8869, 14758, 15821, am,\n",
      "Nearest to created: 19806, what, poor, 18167, 12886, subject, 11224, 19458,\n",
      "Nearest to Irish: talents, 9131, 15497, 19060, 18714, 16195, wasn, roused,\n",
      "Nearest to dependent: witness, legacy, Anxious, 13379, 14986, 18405, 13582, 11632,\n",
      "Nearest to _are_: conduct, mortification, 18758, wondering, forbearing, 11374, 9669, gaped,\n",
      "Nearest to requesting: nature, Phillips, 8829, claim, 13385, entering, 13557, 19015,\n",
      "Nearest to suppressed: 17567, 18075, understanding, deep, 19257, 8739, 17306, ignorant,\n",
      "Nearest to pine: 12002, 13763, 11813, 14179, 15564, 9180, 17296, carelessness,\n",
      "Nearest to incessant: 12546, 16316, 19712, 18551, 20026, 19597, 18145, low,\n",
      "Nearest to unsocial: but, 11322, 11615, sense, 20052, 17436, suit, lover,\n",
      "Nearest to haste: 13289, 11699, What, quick, 8829, 16068, 18419, 19138,\n",
      "Nearest to intend: varied, 11550, 17461, delightful, 13198, 12616, 12164, 17455,\n",
      "Nearest to possessor: Does, 10679, 12174, 14830, beauteous, 8986, overthrown, disagreement,\n",
      "Nearest to occurs: annexed, 18878, curricle, 17783, 13042, harshly, 14762, influence,\n",
      "Nearest to lovely: 18109, 18532, 9457, during, ungenerous, in, 19991, 12750,\n",
      "Nearest to arise: 12245, distinction, 19019, adorned, subjects, 19206, duty, quest,\n",
      "Nearest to miseries: 19960, grown, 13839, 14220, 16563, 9508, 20020, aimed,\n",
      "Nearest to undeceive: 16177, 18177, 9396, 10780, 9469, _Her_, lament, 11239,\n",
      "Nearest to meat: 14363, s_, 15778, 17193, 11613, grace, 14969, 18928,\n",
      "Nearest to HOW: adoration, bestowing, lanes, 15357, 19406, 11020, guessed, according,\n",
      "Nearest to rooms: coincided, 16239, 12989, 19155, comparison, 19541, giving, saw,\n",
      "Nearest to 42: vegetable, praised, 16208, 13145, attach, luckily, maid, defer,\n",
      "Nearest to urged: 16600, wanted, set, way, 13900, 11581, 20027, powers,\n",
      "Nearest to recover: 16752, 18726, 12542, canvas, Section, 15294, loo, picked,\n",
      "Nearest to discompose: urged, 15125, 19040, 12052, 16623, 15553, advising, fine,\n",
      "Nearest to justification: 15910, Service, 10335, 11292, ESQ, 17645, disinterestedness, bewildered,\n",
      "Nearest to resource: following, scolding, 16508, fatigue, 9894, September, 12004, gentleman,\n",
      "Nearest to bowing: 10316, 17528, 10771, hundreds, fault, ennight, 12612, 17899,\n",
      "Nearest to Lory: 13875, 17709, 8582, 16564, 16061, 18325, 12426, 18982,\n",
      "Nearest to meal: stepped, 13262, 9666, 13652, 13391, throughout, banish, 16007,\n",
      "Nearest to direction: beast, 12095, 9104, dear, resisted, 15225, expenses, Behead,\n",
      "Nearest to cultivation: 9899, provoking, North, space, 17743, stateliness, 9288, Surprise,\n",
      "Nearest to inquiries: 12029, 11648, 9607, 8652, required, ten, 16954, 20018,\n",
      "Nearest to survivor: 9769, connections, topics, 19489, 18231, _all_, rejecting, 17942,\n",
      "Nearest to unwilling: pleasant, 19220, dictatorial, patroness, animated, 12842, earnest, 9701,\n",
      "Nearest to rabbit: 16807, strange, 10188, 14175, 18459, model, 14654, ;,\n",
      "Nearest to expence: 19168, perceiving, Conqueror, !’), addressed, 8876, 18188, 12025,\n",
      "Nearest to exist: cambric, 14833, 14611, 11226, 14120, 18893, 16029, fee,\n",
      "Nearest to forms: 19082, omitted, 19980, 16807, 11373, 8927, As, 20027,\n",
      "Nearest to death: says, 9583, attributed, greatest, 19634, found, 12964, 11777,\n",
      "Nearest to damage: 16645, 17569, 17098, 12864, unintelligible, springing, 14037, piquet,\n",
      "Nearest to squeamish: 18403, 12839, 17783, staircase, 9461, 12485, 11438, repinings,\n",
      "Nearest to PERSONS: 19784, 14864, 13180, 19017, 10507, 8984, 19590, remarkable,\n",
      "Nearest to overthrow: possibility, 18088, get, words, necessarily, reflections, 18717, further,\n",
      "Nearest to course: 9376, 19561, 12496, 9575, crowded, strongly, remarkably, 19832,\n",
      "Nearest to interrupt: 20026, 19995, 19616, 18126, 18120, 18414, feelings, 17745,\n",
      "Average loss at step  12000 :  2.18278532296\n",
      "Average loss at step  14000 :  2.1787547245\n",
      "Average loss at step  16000 :  2.0637841741\n",
      "Average loss at step  18000 :  2.021610618\n"
     ]
    }
   ],
   "source": [
    "data_index = 0\n",
    "embeddings = W2V(batch_size, embedding_size, skip_window,\n",
    "            num_skips, valid_size, valid_window,\n",
    "            valid_examples, num_sampled, vocab_size,\n",
    "            num_steps, data, revdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TFKMC(vectors, n_clusters=1000, max_iter=100000):\n",
    "    mbatch = MiniBatchKMeans(n_clusters=n_clusters, batch_size=len(vectors)*.1, max_iter=max_iter)\n",
    "    centroids = mbatch.fit(vectors)\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, word in enumerate(words[:-1]):\n",
    "        if KB.has_node(word) and KB.has_node(words[index+1]):\n",
    "            if KB.has_edge(word, words[index+1]):\n",
    "                node_name = KB.edge[word][words[index+1]]['node']\n",
    "                words.insert(index+1, str(node_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [KB.node[word]['number'] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = collections.Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    counts.update([word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_word = list(filter(lambda datum: revdic[datum] == str(datum), data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nw_revdic = {node[1]['number']: node[0] for node in KB.nodes(True) \n",
    "             if str(node[1]['number']) == node[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nw = np.array(list(map(int, non_word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12344</th>\n",
       "      <th>15176</th>\n",
       "      <th>11660</th>\n",
       "      <th>fourthly</th>\n",
       "      <th>equipment</th>\n",
       "      <th>frighten</th>\n",
       "      <th>16932</th>\n",
       "      <th>junior</th>\n",
       "      <th>13816</th>\n",
       "      <th>19222</th>\n",
       "      <th>...</th>\n",
       "      <th>listener</th>\n",
       "      <th>governed</th>\n",
       "      <th>tureen</th>\n",
       "      <th>tickets</th>\n",
       "      <th>screamed</th>\n",
       "      <th>9992</th>\n",
       "      <th>11899</th>\n",
       "      <th>16122</th>\n",
       "      <th>19186</th>\n",
       "      <th>10868</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12344</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15176</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11660</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fourthly</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equipment</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frighten</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16932</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>junior</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13816</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19222</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inspires</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyelids</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19558</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14952</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starve</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twelve</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19989</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valley</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16751</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13699</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11409</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9487</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14824</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Here</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17625</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERY</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10138</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intend</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inducements</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thick</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentinel</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18250</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19680</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>additions</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18574</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>packing</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10626</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16356</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>format</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unacknowledged</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invalid</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>told</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shorter</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18924</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hanging</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17926</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9506</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9601</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>associated</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listener</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>governed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tureen</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tickets</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screamed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11899</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16122</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19186</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10868</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20063 rows × 20063 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                12344  15176  11660  fourthly  equipment  frighten  16932  \\\n",
       "12344             1.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "15176             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "11660             0.0    0.0    1.0       0.0        0.0       0.0    0.0   \n",
       "fourthly          0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "equipment         0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "frighten          0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "16932             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "junior            0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "13816             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "19222             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "inspires          0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "eyelids           0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "19558             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "14952             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "starve            0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "twelve            0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "19989             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "valley            0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "16751             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "13699             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "11409             0.0    0.0    1.0       0.0        0.0       0.0    0.0   \n",
       "9487              0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "14824             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "12498             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "Here              0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "17625             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "VERY              0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "10138             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "intend            0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "inducements       0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "...               ...    ...    ...       ...        ...       ...    ...   \n",
       "thick             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "sentinel          0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "18250             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "19680             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "additions         0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "18574             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "packing           0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "10626             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "16356             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "format            0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "unacknowledged    0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "invalid           0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "told              0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "shorter           0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "18924             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "hanging           0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "17926             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "9506              0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "9601              0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "associated        0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "listener          0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "governed          0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "tureen            0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "tickets           0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "screamed          0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "9992              0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "11899             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "16122             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "19186             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "10868             0.0    0.0    0.0       0.0        0.0       0.0    0.0   \n",
       "\n",
       "                junior  13816  19222  ...    listener  governed  tureen  \\\n",
       "12344              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "15176              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "11660              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "fourthly           0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "equipment          0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "frighten           0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "16932              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "junior             0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "13816              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "19222              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "inspires           0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "eyelids            0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "19558              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "14952              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "starve             0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "twelve             0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "19989              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "valley             0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "16751              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "13699              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "11409              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "9487               0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "14824              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "12498              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "Here               0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "17625              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "VERY               0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "10138              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "intend             0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "inducements        0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "...                ...    ...    ...  ...         ...       ...     ...   \n",
       "thick              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "sentinel           0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "18250              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "19680              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "additions          0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "18574              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "packing            0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "10626              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "16356              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "format             0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "unacknowledged     0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "invalid            0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "told               0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "shorter            0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "18924              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "hanging            0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "17926              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "9506               0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "9601               0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "associated         0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "listener           0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "governed           0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "tureen             0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "tickets            0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "screamed           0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "9992               0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "11899              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "16122              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "19186              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "10868              0.0    0.0    0.0  ...         0.0       0.0     0.0   \n",
       "\n",
       "                tickets  screamed  9992  11899  16122  19186  10868  \n",
       "12344               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "15176               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "11660               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "fourthly            0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "equipment           0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "frighten            0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "16932               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "junior              0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "13816               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "19222               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "inspires            0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "eyelids             0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "19558               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "14952               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "starve              0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "twelve              0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "19989               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "valley              0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "16751               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "13699               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "11409               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "9487                0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "14824               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "12498               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "Here                0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "17625               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "VERY                0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "10138               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "intend              0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "inducements         0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "...                 ...       ...   ...    ...    ...    ...    ...  \n",
       "thick               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "sentinel            0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "18250               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "19680               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "additions           0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "18574               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "packing             0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "10626               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "16356               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "format              0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "unacknowledged      0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "invalid             0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "told                0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "shorter             0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "18924               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "hanging             0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "17926               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "9506                0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "9601                0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "associated          0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "listener            0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "governed            0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "tureen              0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "tickets             0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "screamed            0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "9992                0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "11899               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "16122               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "19186               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "10868               0.0       0.0   0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[20063 rows x 20063 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.to_pandas_dataframe(KB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.write_graphml(KB, './L1.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('./L!', nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('./embedL!', embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read Gradient Descent Site\n",
    "### 2. Read the Candidate Sampling Thing\n",
    "### 3. Implement KMeans MiniBatch in TensorFlow\n",
    "### 4. Write Graph Adding Code\n",
    "### 5. Write Processing for Transitions into Graph\n",
    "### 6. Implement Word2Vec Using Graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
